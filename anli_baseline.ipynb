{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c468709d",
   "metadata": {},
   "source": [
    "# ANLI Baseline\n",
    "\n",
    "This model illustrates how to use the DeBERTa-v3-base-mnli-fever-anli model to perform specialized inference on the ANLI dataset.\n",
    "This dataset has 184M parameters. It was trained in 2021 on the basis of a BERT-like embedding approach: \n",
    "* The premise and the hypothesis are encoded using the DeBERTa-v3-base contextual encoder\n",
    "* The encodings are then compared on a fine-tuned model to predict a distribution over the classification labels (entailment, contradiction, neutral)\n",
    "\n",
    "Reported accuracy on ANLI is 0.495 (see https://huggingface.co/MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cec0d02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T11:56:44.193395Z",
     "start_time": "2025-07-09T11:56:43.351807Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from random import sample,seed\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9fc0c901ad7473f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T11:56:44.366375Z",
     "start_time": "2025-07-09T11:56:44.231095Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entailment': 6.6, 'neutral': 17.3, 'contradiction': 76.1}\n"
     ]
    }
   ],
   "source": [
    "premise = \"I first thought that I liked the movie, but upon second thought it was actually disappointing.\"\n",
    "hypothesis = \"The movie was good.\"\n",
    "model.to(device) #Lotem: added to explicitly move the model to GPU.\n",
    "input = tokenizer(premise, hypothesis, truncation=True, return_tensors=\"pt\")\n",
    "output = model(input[\"input_ids\"].to(device))  # device = \"cuda:0\" or \"cpu\"\n",
    "prediction = torch.softmax(output[\"logits\"][0], -1).tolist()\n",
    "label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "prediction = {name: round(float(pred) * 100, 1) for pred, name in zip(prediction, label_names)}\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cfe31ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T11:56:44.405528Z",
     "start_time": "2025-07-09T11:56:44.402851Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(premise, hypothesis):\n",
    "    input = tokenizer(premise, hypothesis, truncation=True, return_tensors=\"pt\")\n",
    "    output = model(input[\"input_ids\"].to(device))\n",
    "    prediction = torch.softmax(output[\"logits\"][0], -1).tolist()\n",
    "    prediction = {name: round(float(pred) * 100, 1) for pred, name in zip(prediction, label_names)}\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2954d97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T11:56:44.527317Z",
     "start_time": "2025-07-09T11:56:44.496475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entailment': 0.1, 'neutral': 99.8, 'contradiction': 0.0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\"The weather is nice today.\", \"It is sunny outside.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "923ea5e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T11:56:44.586688Z",
     "start_time": "2025-07-09T11:56:44.582315Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_prediction(pred_dict):\n",
    "    if pred_dict[\"entailment\"] > pred_dict[\"contradiction\"]  and pred_dict[\"entailment\"] > pred_dict[\"neutral\"]:\n",
    "        return \"entailment\"\n",
    "    elif pred_dict[\"contradiction\"] > pred_dict[\"entailment\"] and pred_dict[\"contradiction\"] > pred_dict[\"neutral\"]:\n",
    "        return \"contradiction\"\n",
    "    else:\n",
    "        return \"neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af257dff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T11:56:44.682748Z",
     "start_time": "2025-07-09T11:56:44.665304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(evaluate(\"The weather is nice today.\", \"It is sunny outside.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "929632f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T11:56:44.776821Z",
     "start_time": "2025-07-09T11:56:44.755656Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'entailment'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(evaluate(\"It is sunny outside.\", \"The weather is nice today.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "747c0cb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T11:56:44.848063Z",
     "start_time": "2025-07-09T11:56:44.832238Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'contradiction'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(evaluate(\"It is sunny outside.\", \"The weather is terrible today.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ab422d",
   "metadata": {},
   "source": [
    "## Load ANLI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0438789b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T11:56:49.388735Z",
     "start_time": "2025-07-09T11:56:44.916144Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"facebook/anli\")\n",
    "dataset = dataset.filter(lambda x: x['reason'] != None and x['reason'] != \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e59927ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T11:56:49.432751Z",
     "start_time": "2025-07-09T11:56:49.429300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train_r1: Dataset({\n",
       "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
       "        num_rows: 2923\n",
       "    })\n",
       "    dev_r1: Dataset({\n",
       "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test_r1: Dataset({\n",
       "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    train_r2: Dataset({\n",
       "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
       "        num_rows: 4861\n",
       "    })\n",
       "    dev_r2: Dataset({\n",
       "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test_r2: Dataset({\n",
       "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    train_r3: Dataset({\n",
       "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
       "        num_rows: 13375\n",
       "    })\n",
       "    dev_r3: Dataset({\n",
       "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
       "        num_rows: 1200\n",
       "    })\n",
       "    test_r3: Dataset({\n",
       "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
       "        num_rows: 1200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8262068",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T11:56:49.507844Z",
     "start_time": "2025-07-09T11:56:49.504777Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the ANLI dataset\n",
    "from tqdm import tqdm\n",
    "def evaluate_on_dataset(dataset):\n",
    "    results = []\n",
    "    label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "    for example in tqdm(dataset):\n",
    "        premise = example['premise']\n",
    "        hypothesis = example['hypothesis']\n",
    "        prediction = evaluate(premise, hypothesis)\n",
    "        results.append({\n",
    "            'premise': premise,\n",
    "            'hypothesis': hypothesis,\n",
    "            'prediction': prediction,\n",
    "            'pred_label': get_prediction(prediction),\n",
    "            'gold_label': label_names[example['label']],\n",
    "            'reason': example['reason']\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f858feae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T11:57:03.376423Z",
     "start_time": "2025-07-09T11:56:49.579615Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [01:39<00:00, 12.04it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_test_r3 = evaluate_on_dataset(dataset['test_r3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8efb717",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T11:57:03.385117Z",
     "start_time": "2025-07-09T11:57:03.381586Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'premise': \"It is Sunday today, let's take a look at the most popular posts of the last couple of days. Most of the articles this week deal with the iPhone, its future version called the iPhone 8 or iPhone Edition, and new builds of iOS and macOS. There are also some posts that deal with the iPhone rival called the Galaxy S8 and some other interesting stories. The list of the most interesting articles is available below. Stay tuned for more rumors and don't forget to follow us on Twitter.\",\n",
       "  'hypothesis': 'The day of the passage is usually when Christians praise the lord together',\n",
       "  'prediction': {'entailment': 2.4, 'neutral': 97.4, 'contradiction': 0.2},\n",
       "  'pred_label': 'neutral',\n",
       "  'gold_label': 'entailment',\n",
       "  'reason': \"Sunday is considered Lord's Day\"},\n",
       " {'premise': 'By The Associated Press WELLINGTON, New Zealand (AP) — All passengers and crew have survived a crash-landing of a plane in a lagoon in the Federated States of Micronesia. WELLINGTON, New Zealand (AP) — All passengers and crew have survived a crash-landing of a plane in a lagoon in the Federated States of Micronesia. Copyright © 2018 The Associated Press. All rights reserved. This material may not be published, broadcast, written or redistributed.',\n",
       "  'hypothesis': 'No children were killed in the accident.',\n",
       "  'prediction': {'entailment': 0.1, 'neutral': 99.9, 'contradiction': 0.0},\n",
       "  'pred_label': 'neutral',\n",
       "  'gold_label': 'entailment',\n",
       "  'reason': 'The context confirms that everybody survived the accident, so there is no way that a child was killed.'},\n",
       " {'premise': 'Tokyo - Food group Nestle is seeking to lure Japanese holiday shoppers with a taste for fine snacking with a gold-wrapped Kit Kat chocolate bar. The single finger Kit Kat is wrapped in a thin layer of gold leaf. Only 500 of the bars go on sale from Dec. 29 with a price tag of around 2,016 yen ($16). The Kit Kat chocolate bar made its debut in Japan in 1973 and since then a variety of flavors -- from green tea to wasabi -- have been produced.',\n",
       "  'hypothesis': 'Japanese like kit kat. ',\n",
       "  'prediction': {'entailment': 84.0, 'neutral': 15.9, 'contradiction': 0.1},\n",
       "  'pred_label': 'entailment',\n",
       "  'gold_label': 'entailment',\n",
       "  'reason': 'according to the text, The Kit Kat chocolate bar made its debut in Japan in 1973 and since then a variety of flavors -- from green tea to wasabi -- have been produced, which means if  they have been so many produced it is because they like it. '},\n",
       " {'premise': 'Governor Greg Abbott has called for a statewide show of support for law enforcement Friday, July 7. Locally, a 15-minute program is planned at 9 a.m. at Memorial Lane Park, 550 N. Travis St. The governor is asking law enforcement officers to turn on red and blue flashing lights for one-minute at 10 a.m. Multiple law enforcement officers were shot and killed in Dallas one year ago.',\n",
       "  'hypothesis': 'Law enforcement officers and the people at the Travis St. memorial do not show their support at the same time.',\n",
       "  'prediction': {'entailment': 11.9, 'neutral': 75.8, 'contradiction': 12.3},\n",
       "  'pred_label': 'neutral',\n",
       "  'gold_label': 'entailment',\n",
       "  'reason': 'The Travis St.memorial program begins at 9 a.m. Law enforcement officers were asked to turn on red and blue flashing lights for one-minute at 10 a.m.'},\n",
       " {'premise': 'Sept 4 (Reuters) - J.P. Morgan Asset Management, a unit of JPMorgan Chase & Co, said it appointed Pietro Grassano the new country head for France. Based in Paris, Grassano started in his new role on Sept. 1, J.P. Morgan Asset Management said in a statement. Grassano, who has been with the company since 2002, was previously the head of sales for Italy, covering wholesale and retail distribution. He has earlier worked at BNP Paribas Asset Management.',\n",
       "  'hypothesis': 'Pietro Grassano was once the country head for France.',\n",
       "  'prediction': {'entailment': 2.9, 'neutral': 55.1, 'contradiction': 42.0},\n",
       "  'pred_label': 'neutral',\n",
       "  'gold_label': 'entailment',\n",
       "  'reason': '\"J.P. Morgan Asset Management, a unit of JPMorgan Chase & Co, said it appointed Pietro Grassano the new country head for France.\" I think it was difficult because I worded it past tense, \"He was ONCE the country head\", but I believe that statement is true because it is past Sept 1 when he was appointed.'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_r3[:5]  # Display the first 5 predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8e1258",
   "metadata": {},
   "source": [
    "## Evaluate Metrics\n",
    "\n",
    "Let's use the huggingface `evaluate` package to compute the performance of the baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e2e9027",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T11:57:07.158932Z",
     "start_time": "2025-07-09T11:57:03.483511Z"
    }
   },
   "outputs": [],
   "source": [
    "from evaluate import load,combine\n",
    "\n",
    "accuracy = load(\"accuracy\")\n",
    "precision = load(\"precision\")\n",
    "recall = load(\"recall\")\n",
    "f1 = load(\"f1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ab24e1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T11:57:10.911415Z",
     "start_time": "2025-07-09T11:57:07.201923Z"
    }
   },
   "outputs": [],
   "source": [
    "clf_metrics = combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76fe4bc9d4fde693",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T11:57:11.021441Z",
     "start_time": "2025-07-09T11:57:10.993100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6666666666666666,\n",
       " 'f1': 0.6666666666666666,\n",
       " 'precision': 1.0,\n",
       " 'recall': 0.5}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_metrics.compute(predictions=[0, 1, 0], references=[0, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0909d58b",
   "metadata": {},
   "source": [
    "## Your Turn\n",
    "\n",
    "Compute the classification metrics on the baseline model on each section of the ANLI dataset.\n",
    "\n",
    "https://www.kaggle.com/code/faijanahamadkhan/llm-evaluation-framework-hugging-face provides good documentation on how to use the Huggingface evaluate library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efccccb4062faf0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T11:57:48.131283Z",
     "start_time": "2025-07-09T11:57:11.108207Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:37<00:00, 10.27it/s]\n",
      "100%|██████████| 1000/1000 [01:20<00:00, 12.46it/s]\n",
      "100%|██████████| 1200/1200 [01:38<00:00, 12.24it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.filter(lambda x: x['reason'] != None and x['reason'] != \"\")\n",
    "\n",
    "pred_test_r1 = evaluate_on_dataset(dataset['test_r1'])\n",
    "pred_test_r2 = evaluate_on_dataset(dataset['test_r2'])\n",
    "pred_test_r3 = evaluate_on_dataset(dataset['test_r3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae0ceb2a76935c9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T11:57:48.176880Z",
     "start_time": "2025-07-09T11:57:48.173789Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_labels_r1 = [x['pred_label'] for x in pred_test_r1]\n",
    "gold_labels_r1 = [x['gold_label'] for x in pred_test_r1]\n",
    "pred_labels_r2 = [x['pred_label'] for x in pred_test_r2]\n",
    "gold_labels_r2 = [x['gold_label'] for x in pred_test_r2]\n",
    "pred_labels_r3 = [x['pred_label'] for x in pred_test_r3]\n",
    "gold_labels_r3 = [x['gold_label'] for x in pred_test_r3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b63175833eca6be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T11:57:48.285479Z",
     "start_time": "2025-07-09T11:57:48.259892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report on r1_test\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.75      0.68      0.71       333\n",
      "   entailment       0.70      0.73      0.71       334\n",
      "      neutral       0.70      0.73      0.71       333\n",
      "\n",
      "     accuracy                           0.71      1000\n",
      "    macro avg       0.71      0.71      0.71      1000\n",
      " weighted avg       0.71      0.71      0.71      1000\n",
      "\n",
      "Classification report on r2_test\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.55      0.50      0.53       333\n",
      "   entailment       0.54      0.57      0.55       334\n",
      "      neutral       0.55      0.57      0.56       333\n",
      "\n",
      "     accuracy                           0.55      1000\n",
      "    macro avg       0.55      0.55      0.55      1000\n",
      " weighted avg       0.55      0.55      0.55      1000\n",
      "\n",
      "Classification report on r3_test\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.51      0.42      0.46       396\n",
      "   entailment       0.56      0.57      0.56       402\n",
      "      neutral       0.43      0.50      0.46       402\n",
      "\n",
      "     accuracy                           0.49      1200\n",
      "    macro avg       0.50      0.49      0.49      1200\n",
      " weighted avg       0.50      0.49      0.49      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "#Classification report on r1_test\n",
    "print(\"Classification report on r1_test\")\n",
    "print(classification_report(gold_labels_r1, pred_labels_r1))\n",
    "print(\"Classification report on r2_test\")\n",
    "print(classification_report(gold_labels_r2, pred_labels_r2))\n",
    "print(\"Classification report on r3_test\")\n",
    "print(classification_report(gold_labels_r3, pred_labels_r3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb747ea17586db1",
   "metadata": {},
   "source": [
    "## Investigate Errors of the NLI Model\n",
    "First, we will sample 20 errors from the baseline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f0d6ca4d0ec878a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T11:57:48.376553Z",
     "start_time": "2025-07-09T11:57:48.369896Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_test_r1_errors = [x for x in pred_test_r1 if x['pred_label'] != x['gold_label']]\n",
    "pred_test_r2_errors = [x for x in pred_test_r2 if x['pred_label'] != x['gold_label']]\n",
    "pred_test_r3_errors = [x for x in pred_test_r3 if x['pred_label'] != x['gold_label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1475e8e5b8f60a54",
   "metadata": {},
   "source": [
    "We will now print some statistics about each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfd766b8e5ca18c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T11:57:48.435549Z",
     "start_time": "2025-07-09T11:57:48.433024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of mistakes in test_r1:\t288\n",
      "Amount of mistakes in test_r2:\t453\n",
      "Amount of mistakes in test_r3:\t606\n"
     ]
    }
   ],
   "source": [
    "print(f\"Amount of mistakes in test_r1:\\t{len(pred_test_r1_errors)}\")\n",
    "print(f\"Amount of mistakes in test_r2:\\t{len(pred_test_r2_errors)}\")\n",
    "print(f\"Amount of mistakes in test_r3:\\t{len(pred_test_r3_errors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7957f4a5c146a195",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T11:57:48.541916Z",
     "start_time": "2025-07-09T11:57:48.539583Z"
    }
   },
   "outputs": [],
   "source": [
    "seed(0)\n",
    "samples = sample(pred_test_r1_errors,6)+sample(pred_test_r2_errors,7)+sample(pred_test_r3_errors,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd00c43fd9400a94",
   "metadata": {},
   "source": [
    "We will now nicely print the 20 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1ada86bab81d797",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T11:57:48.677758Z",
     "start_time": "2025-07-09T11:57:48.658484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "🧠 Sample #1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "📘 Premise:\n",
      "Sully Diaz (July 12, 1960; New York City) is a Spanish actress and singer born to Sephardic parents\n",
      "from, Puerto Rico. Sully's career started in Puerto Rican television with her first starring role as\n",
      "Coralito in the \"novela\" called \"Coralito\". \"Coralito\" was her first starring role. Sully was\n",
      "invited to star in various soap operas in Puerto Rico, Venezuela and Argentina.\n",
      "\n",
      "📗 Hypothesis:\n",
      "Sully Diaz was born in the United States.\n",
      "\n",
      "🔍 Prediction Scores:\n",
      "  Entailment   : 1.0%\n",
      "  Neutral      : 0.6%\n",
      "  Contradiction: 98.3%\n",
      "\n",
      "✅ Predicted Label: contradiction\n",
      "🎯 Gold Label     : entailment\n",
      "\n",
      "💡 Reasoning:\n",
      "Excerpt states she was born in NYC, which is in the USA. Model maybe got confused by the fact her\n",
      "parents were from Puerto Rico.\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "🧠 Sample #2\n",
      "----------------------------------------------------------------------------------------------------\n",
      "📘 Premise:\n",
      "The Stinky Puffs were an early 90's rock band started by then seven-year-old Simon Fair Timony,\n",
      "then-stepson of Jad Fair, and by Cody Linn Ranaldo, son of Sonic Youth guitarist Lee Ranaldo. After\n",
      "a 7\" single an LP followed in 1995 titled \"A Little Tiny Smelly Bit of...the Stinky Puffs\" and an EP\n",
      "in 1996 titled \"Songs and Advice for Kids Who Have Been Left Behind\".\n",
      "\n",
      "📗 Hypothesis:\n",
      "Jad Fair married Simon Fair Timony's mother.\n",
      "\n",
      "🔍 Prediction Scores:\n",
      "  Entailment   : 0.1%\n",
      "  Neutral      : 99.7%\n",
      "  Contradiction: 0.2%\n",
      "\n",
      "✅ Predicted Label: neutral\n",
      "🎯 Gold Label     : entailment\n",
      "\n",
      "💡 Reasoning:\n",
      "Jad Fair was Simon Fair Timony's step father, so he would have married his mother.  I think it was\n",
      "difficult because the mother was never mentioned.\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "🧠 Sample #3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "📘 Premise:\n",
      ".lgbt is a sponsored top-level domain for the LGBT community, sponsored by Afilias. The domain name\n",
      "was delegated to the Root Zone on 18 July 2014. The creation of .lgbt is meant to promote diversity\n",
      "and LGBT businesses, and is open to LGBT businesses, organizations, and anyone wishing to reach the\n",
      "LGBT community.\n",
      "\n",
      "📗 Hypothesis:\n",
      "The .lgbt domain is for lgbt small businesses.\n",
      "\n",
      "🔍 Prediction Scores:\n",
      "  Entailment   : 1.7%\n",
      "  Neutral      : 98.0%\n",
      "  Contradiction: 0.2%\n",
      "\n",
      "✅ Predicted Label: neutral\n",
      "🎯 Gold Label     : entailment\n",
      "\n",
      "💡 Reasoning:\n",
      "It never directly said if it was for small businesses or all businesses in general.\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "🧠 Sample #4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "📘 Premise:\n",
      "Julian Peter McDonald Clary (born 25 May 1959) is an English comedian and novelist. Openly gay,\n",
      "Clary began appearing on television in the mid-1980s and became known for his deliberately\n",
      "stereotypical camp style. Since then he has also acted in films, television and stage productions,\n",
      "and was the winner of \"Celebrity Big Brother 10\" in 2012.\n",
      "\n",
      "📗 Hypothesis:\n",
      "Julian Peter McDonald Clary was less than 30 years old when he began his television career.\n",
      "\n",
      "🔍 Prediction Scores:\n",
      "  Entailment   : 3.2%\n",
      "  Neutral      : 0.8%\n",
      "  Contradiction: 96.0%\n",
      "\n",
      "✅ Predicted Label: contradiction\n",
      "🎯 Gold Label     : entailment\n",
      "\n",
      "💡 Reasoning:\n",
      "The statement is true because Julian Peter McDonald Clary was around 26 when he started in\n",
      "television, according to the facts given.  I think this fooled the model because it is vague/nuanced\n",
      "enough for the model not to be able to determine the correct calculation.\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "🧠 Sample #5\n",
      "----------------------------------------------------------------------------------------------------\n",
      "📘 Premise:\n",
      "The Best of David Bowie 1974/1979 is a compilation album by David Bowie released in 1998 (see 1998\n",
      "in music). It follows \"The Best of David Bowie 1969/1974\" (1997) and includes material released\n",
      "between 1974–1979. This album was also included as the second disc of the compilation \"The Platinum\n",
      "Collection\" (2005/2006).\n",
      "\n",
      "📗 Hypothesis:\n",
      "David Bowie didn't only release an album in 1998 but also in 1979.\n",
      "\n",
      "🔍 Prediction Scores:\n",
      "  Entailment   : 98.6%\n",
      "  Neutral      : 0.7%\n",
      "  Contradiction: 0.7%\n",
      "\n",
      "✅ Predicted Label: entailment\n",
      "🎯 Gold Label     : neutral\n",
      "\n",
      "💡 Reasoning:\n",
      "We don't know if he released an album in 1979. maybe the years confused the system\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "🧠 Sample #6\n",
      "----------------------------------------------------------------------------------------------------\n",
      "📘 Premise:\n",
      "Gyula Trebitsch (3 November 1914 - 12 December 2005) was a German film producer born in Budapest,\n",
      "Hungary. He was nominated in 1956 for the Academy Award for Best Foreign Language Film along with\n",
      "Walter Koppel for their film \"The Captain of Kopenick\".\n",
      "\n",
      "📗 Hypothesis:\n",
      "Gyula Trebitsch was nominated for the Academy Award for Best Foreign Language Film for his work on\n",
      "\"The Captain of Kopenick\" at the age of 43.\n",
      "\n",
      "🔍 Prediction Scores:\n",
      "  Entailment   : 33.7%\n",
      "  Neutral      : 53.0%\n",
      "  Contradiction: 13.3%\n",
      "\n",
      "✅ Predicted Label: neutral\n",
      "🎯 Gold Label     : contradiction\n",
      "\n",
      "💡 Reasoning:\n",
      "He was nominated in 1956 and didn't turn 43 until 1957. The system has trouble with ages and\n",
      "birthdays.\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "🧠 Sample #7\n",
      "----------------------------------------------------------------------------------------------------\n",
      "📘 Premise:\n",
      "The Samsung Galaxy Tab 8.9 is an Android-based tablet computer designed and manufactured by Samsung,\n",
      "introduced on 22 March 2011 at CTIA wireless convention in its Samsung Unpacked event in Orlando. It\n",
      "is part of the Samsung Galaxy Tab series, and features an 8.9-inch display and a 1 GHz dual-core\n",
      "Nvidia Tegra 2 processor.\n",
      "\n",
      "📗 Hypothesis:\n",
      "Samsung Galaxy has about 9 inch display\n",
      "\n",
      "🔍 Prediction Scores:\n",
      "  Entailment   : 26.9%\n",
      "  Neutral      : 15.0%\n",
      "  Contradiction: 58.1%\n",
      "\n",
      "✅ Predicted Label: contradiction\n",
      "🎯 Gold Label     : entailment\n",
      "\n",
      "💡 Reasoning:\n",
      "The display is about 8.9 inches.\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "🧠 Sample #8\n",
      "----------------------------------------------------------------------------------------------------\n",
      "📘 Premise:\n",
      "\"May the Bird of Paradise Fly Up Your Nose\" is a 1965 novelty song performed by Little Jimmy\n",
      "Dickens. It was Dickens' most successful single on the U.S. country music chart. It spent two weeks\n",
      "at No. 1 that November, and stayed on the chart for a total of 18 weeks. On the overall \"Billboard\"\n",
      "Hot 100 the song peaked at No. 15.\n",
      "\n",
      "📗 Hypothesis:\n",
      "\"May the Bird of Paradise Fly Up Your Nose\" was not on the charts for 6 months\n",
      "\n",
      "🔍 Prediction Scores:\n",
      "  Entailment   : 10.8%\n",
      "  Neutral      : 1.3%\n",
      "  Contradiction: 87.9%\n",
      "\n",
      "✅ Predicted Label: contradiction\n",
      "🎯 Gold Label     : entailment\n",
      "\n",
      "💡 Reasoning:\n",
      "\"May the Bird of Paradise Fly Up Your Nose\" was on the charts for 18 weeks shorter than 6 months.\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "🧠 Sample #9\n",
      "----------------------------------------------------------------------------------------------------\n",
      "📘 Premise:\n",
      "Alexandre \"Xande\" Ribeiro (born January 20, 1981 in Manaus-Amazonas, Brazil), is a Brazilian Jiu-\n",
      "Jitsu practitioner, mixed martial artist and submission wrestler. He is a two-time World (Mundial)\n",
      "Black Belt Absolute (open weight) World Jiu-Jitsu Champion, five-time World (Mundial) Black Belt\n",
      "Heavy Weight Champion, and three-time World Black Belt Pro Division Champion.\n",
      "\n",
      "📗 Hypothesis:\n",
      "Alexandre \"Xande\" Ribeiro is 38 Years old\n",
      "\n",
      "🔍 Prediction Scores:\n",
      "  Entailment   : 26.8%\n",
      "  Neutral      : 1.2%\n",
      "  Contradiction: 72.0%\n",
      "\n",
      "✅ Predicted Label: contradiction\n",
      "🎯 Gold Label     : entailment\n",
      "\n",
      "💡 Reasoning:\n",
      "Using his birthdate given and the current date he has an age of 38 Years old. I checked this simply\n",
      "on wikipedia as well.\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "🧠 Sample #10\n",
      "----------------------------------------------------------------------------------------------------\n",
      "📘 Premise:\n",
      "Bronwen (] ) is a Welsh feminine given name. It is closely associated with the similar name\n",
      "\"Branwen\", which appears in medieval Welsh literature. Used in Wales since the 19th century, it was\n",
      "introduced to the English-speaking public at large by a character in the Richard Llewellyn novel\n",
      "\"How Green Was My Valley\" (1939).\n",
      "\n",
      "📗 Hypothesis:\n",
      "Bronwen was a named based on a novel\n",
      "\n",
      "🔍 Prediction Scores:\n",
      "  Entailment   : 5.3%\n",
      "  Neutral      : 51.1%\n",
      "  Contradiction: 43.5%\n",
      "\n",
      "✅ Predicted Label: neutral\n",
      "🎯 Gold Label     : entailment\n",
      "\n",
      "💡 Reasoning:\n",
      "Yes it was introduced to the English-speaking public at large by a character in the Richard\n",
      "Llewellyn novel \"How Green Was My Valley\"\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "🧠 Sample #11\n",
      "----------------------------------------------------------------------------------------------------\n",
      "📘 Premise:\n",
      "On 10 September 2016, a man armed with a knife attacked another man walking his dog in Minto, a\n",
      "suburb of Sydney, Australia. As he stabbed the victim the accused allegedly shouted \"someone is\n",
      "going to die today.\" The perpetrator subsequently sought to attack police, but was arrested a short\n",
      "time later.\n",
      "\n",
      "📗 Hypothesis:\n",
      "The perpetrator sought to attack the police from the beginning\n",
      "\n",
      "🔍 Prediction Scores:\n",
      "  Entailment   : 0.1%\n",
      "  Neutral      : 2.4%\n",
      "  Contradiction: 97.5%\n",
      "\n",
      "✅ Predicted Label: contradiction\n",
      "🎯 Gold Label     : neutral\n",
      "\n",
      "💡 Reasoning:\n",
      "Text says he sought to attack the police, but didn't say if it was from the beginning\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "🧠 Sample #12\n",
      "----------------------------------------------------------------------------------------------------\n",
      "📘 Premise:\n",
      "The Path Between the Seas: The Creation of the Panama Canal, 1870–1914 (1977) is a book by the\n",
      "American historian David McCullough, published by Simon & Schuster. It won the U.S. National Book\n",
      "Award in History, the Francis Parkman Prize, the Samuel Eliot Morison Award and the Cornelius Ryan\n",
      "Award.\n",
      "\n",
      "📗 Hypothesis:\n",
      "The Panama Canal was completed before David McCullough was born.\n",
      "\n",
      "🔍 Prediction Scores:\n",
      "  Entailment   : 15.0%\n",
      "  Neutral      : 1.3%\n",
      "  Contradiction: 83.7%\n",
      "\n",
      "✅ Predicted Label: contradiction\n",
      "🎯 Gold Label     : neutral\n",
      "\n",
      "💡 Reasoning:\n",
      "The statement fits into the correct category because the excerpt states the date that the Panama\n",
      "Canal was completed in the book title, but does not say when the author was born. The system may\n",
      "have been confused by the other dates in the excerpt.\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "🧠 Sample #13\n",
      "----------------------------------------------------------------------------------------------------\n",
      "📘 Premise:\n",
      "\"Anna Sun\" is a song by American rock band Walk the Moon, originally for their 2010 album \"I Want! I\n",
      "Want!\". The song was written by band members Adrian Galvin, Nick Lerangis, Nicholas Petricca and\n",
      "Adam Reifsnyder about Adrian's ex-girlfriend, Anna Ceravolo. It was included on the band's 2012\n",
      "major-label debut album, \"Walk the Moon\". It was released as a commercial single on February 7,\n",
      "2012.\n",
      "\n",
      "📗 Hypothesis:\n",
      "\"Anna Sun\" is a song by American rock band Walk the Moon, originally for their 2010 album \"I Want! I\n",
      "Want! I Want!\".\n",
      "\n",
      "🔍 Prediction Scores:\n",
      "  Entailment   : 73.5%\n",
      "  Neutral      : 2.9%\n",
      "  Contradiction: 23.5%\n",
      "\n",
      "✅ Predicted Label: entailment\n",
      "🎯 Gold Label     : contradiction\n",
      "\n",
      "💡 Reasoning:\n",
      "It's I want I want, not I want I want I want\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "🧠 Sample #14\n",
      "----------------------------------------------------------------------------------------------------\n",
      "📘 Premise:\n",
      "How to own and love a pit bull dog<br>Make sure you can properly care for your pit bull. Pit bulls\n",
      "can make great companions and wonderful additions to your family. However, you'll need to be able to\n",
      "meet the demands that proper pit bull care will call for.\n",
      "\n",
      "📗 Hypothesis:\n",
      "Pit Bulls are a cats best friend\n",
      "\n",
      "🔍 Prediction Scores:\n",
      "  Entailment   : 0.0%\n",
      "  Neutral      : 0.3%\n",
      "  Contradiction: 99.7%\n",
      "\n",
      "✅ Predicted Label: contradiction\n",
      "🎯 Gold Label     : neutral\n",
      "\n",
      "💡 Reasoning:\n",
      "the article makes no reference on how pit bulls get a long with other animals\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "🧠 Sample #15\n",
      "----------------------------------------------------------------------------------------------------\n",
      "📘 Premise:\n",
      "Co-producing the film is Happy Madison, the company owned by Sandler, who has been a compatriot of\n",
      "Schneider's since they met early in their careers, as mutually struggling stand-up comedians in Los\n",
      "Angeles.\n",
      "\n",
      "📗 Hypothesis:\n",
      "comedians in Los Angeles struggle\n",
      "\n",
      "🔍 Prediction Scores:\n",
      "  Entailment   : 97.8%\n",
      "  Neutral      : 2.1%\n",
      "  Contradiction: 0.1%\n",
      "\n",
      "✅ Predicted Label: entailment\n",
      "🎯 Gold Label     : neutral\n",
      "\n",
      "💡 Reasoning:\n",
      "When they first start out, comedians in Los Angeles will probably struggle. But once you have\n",
      "established yourself like these two, who started their own production company, they are not\n",
      "struggling at all. Just because you're a comic in LA doesn't mean you will always struggle.\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "🧠 Sample #16\n",
      "----------------------------------------------------------------------------------------------------\n",
      "📘 Premise:\n",
      "My friend<br>My friend owns a business. A customer came into his business. The customer ordered a\n",
      "drink. My friend gave the customer a drink. The customer paid my friend for the drink.\n",
      "\n",
      "📗 Hypothesis:\n",
      "The customer is out of money\n",
      "\n",
      "🔍 Prediction Scores:\n",
      "  Entailment   : 0.1%\n",
      "  Neutral      : 5.5%\n",
      "  Contradiction: 94.4%\n",
      "\n",
      "✅ Predicted Label: contradiction\n",
      "🎯 Gold Label     : neutral\n",
      "\n",
      "💡 Reasoning:\n",
      "we can't know that the customer spent all their money, or had some left over\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "🧠 Sample #17\n",
      "----------------------------------------------------------------------------------------------------\n",
      "📘 Premise:\n",
      "The key is of course in the words of section 93 which are rooted in 19th century history and, to\n",
      "some extent of course, in 18th century history because that is where these particular provisions\n",
      "flowed from, the capitulations of 1759, the Treaty of Paris of 1763 and the Quebec Act of 1774.\n",
      "\n",
      "📗 Hypothesis:\n",
      "the key is course in words of section 93 which gives the details of treaty of paris of 1763\n",
      "\n",
      "🔍 Prediction Scores:\n",
      "  Entailment   : 0.2%\n",
      "  Neutral      : 99.4%\n",
      "  Contradiction: 0.4%\n",
      "\n",
      "✅ Predicted Label: neutral\n",
      "🎯 Gold Label     : entailment\n",
      "\n",
      "💡 Reasoning:\n",
      "the 18th century deals the treaty of paris ,quebec act and capitulations of 1759\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "🧠 Sample #18\n",
      "----------------------------------------------------------------------------------------------------\n",
      "📘 Premise:\n",
      "Jo immediately sat up , put her hands in her pockets , and began to whistle .<br>`` Do n't , Jo\n",
      ".<br>It 's so boyish ! ''<br>`` That 's why I do it . ''<br>`` I detest rude , unladylike girls !\n",
      "''<br>`` I hate affected , niminy-piminy chits ! ''<br>`` Birds in their little nests agree , ''\n",
      "sang Beth , the peacemaker , with such a funny face that both sharp voices softened to a laugh , and\n",
      "the `` pecking '' ended for that time .\n",
      "\n",
      "📗 Hypothesis:\n",
      "Beth and Jo detest birds in their little nests.\n",
      "\n",
      "🔍 Prediction Scores:\n",
      "  Entailment   : 0.2%\n",
      "  Neutral      : 0.5%\n",
      "  Contradiction: 99.3%\n",
      "\n",
      "✅ Predicted Label: contradiction\n",
      "🎯 Gold Label     : neutral\n",
      "\n",
      "💡 Reasoning:\n",
      "We can't truly know if Beth and Jo detest birds in their little nests. The system maybe got confused\n",
      "by similar phrasing in the excerpt.\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "🧠 Sample #19\n",
      "----------------------------------------------------------------------------------------------------\n",
      "📘 Premise:\n",
      "April 22 Insurer ACE Ltd reported a quarterly profit that beat analysts' estimates as commercial\n",
      "insurance rates continued to improve in the United States. The company's net income fell to $953\n",
      "million, or $2.77 per share, for the first quarter from $973 million, or $2.84 per share, a year\n",
      "earlier. The company's operating income was $2.17 per share. Analysts on average had expected\n",
      "operating income of $1.94 per share, according to Thomson Reuters I/B/E/S.\n",
      "\n",
      "📗 Hypothesis:\n",
      "The analysists were disappointed by the quarterly profits.\n",
      "\n",
      "🔍 Prediction Scores:\n",
      "  Entailment   : 39.6%\n",
      "  Neutral      : 56.1%\n",
      "  Contradiction: 4.3%\n",
      "\n",
      "✅ Predicted Label: neutral\n",
      "🎯 Gold Label     : contradiction\n",
      "\n",
      "💡 Reasoning:\n",
      "The company reported better than expected profits.\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "🧠 Sample #20\n",
      "----------------------------------------------------------------------------------------------------\n",
      "📘 Premise:\n",
      "How to dress up a boy like a girl<br>Shave his legs, armpits, and face. For a boy to dress like a\n",
      "girl, he needs to have no leg, facial, or armpit hair. Have him take a shower and shave his legs,\n",
      "armpits, and face.\n",
      "\n",
      "📗 Hypothesis:\n",
      "Have him take a shower and shave his lower arms, upper back, and face.\n",
      "\n",
      "🔍 Prediction Scores:\n",
      "  Entailment   : 0.7%\n",
      "  Neutral      : 92.4%\n",
      "  Contradiction: 6.9%\n",
      "\n",
      "✅ Predicted Label: neutral\n",
      "🎯 Gold Label     : contradiction\n",
      "\n",
      "💡 Reasoning:\n",
      "It lists different body parts to be shaved, not the ones I listed. It's difficult because I guess\n",
      "the sentence is overall similar enough to the text to confuse the system.\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "def print_nli_errors(samples, width=100):\n",
    "    for i, sample in enumerate(samples, 1):\n",
    "        print(f\"\\n{'='*width}\")\n",
    "        print(f\"🧠 Sample #{i}\")\n",
    "        print(f\"{'-'*width}\")\n",
    "\n",
    "        print(\"📘 Premise:\")\n",
    "        print(textwrap.fill(sample['premise'], width=width))\n",
    "\n",
    "        print(\"\\n📗 Hypothesis:\")\n",
    "        print(textwrap.fill(sample['hypothesis'], width=width))\n",
    "\n",
    "        print(\"\\n🔍 Prediction Scores:\")\n",
    "        for label, score in sample['prediction'].items():\n",
    "            print(f\"  {label.capitalize():<13}: {score}%\")\n",
    "\n",
    "        print(f\"\\n✅ Predicted Label: {sample['pred_label']}\")\n",
    "        print(f\"🎯 Gold Label     : {sample['gold_label']}\")\n",
    "\n",
    "        print(\"\\n💡 Reasoning:\")\n",
    "        print(textwrap.fill(sample['reason'], width=width))\n",
    "        print(f\"{'='*width}\")\n",
    "\n",
    "# Then use:\n",
    "print_nli_errors(samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772fede49a2c144e",
   "metadata": {},
   "source": [
    "One of the runs provided us the following results:\n",
    "## NLI Model Error Samples\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Sample #1\n",
    "\n",
    "**📘 Premise:**\n",
    "Sully Diaz (July 12, 1960; New York City) is a Spanish actress and singer born to Sephardic parents from Puerto Rico. Sully's career started in Puerto Rican television with her first starring role as Coralito in the \"novela\" called \"Coralito\". \"Coralito\" was her first starring role. Sully was invited to star in various soap operas in Puerto Rico, Venezuela and Argentina.\n",
    "\n",
    "**📗 Hypothesis:**\n",
    "Sully Diaz was born in the United States.\n",
    "\n",
    "**🔍 Prediction Scores:**\n",
    "\n",
    "* Entailment: 1.0%\n",
    "* Neutral: 0.6%\n",
    "* Contradiction: 98.3%\n",
    "\n",
    "**✅ Predicted Label:** contradiction\n",
    "**🎯 Gold Label:** entailment\n",
    "\n",
    "**💡 Reasoning:**\n",
    "Excerpt states she was born in NYC, which is in the USA. Model maybe got confused by the fact her parents were from Puerto Rico.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Sample #2\n",
    "\n",
    "**📘 Premise:**\n",
    "The Stinky Puffs were an early 90's rock band started by then seven-year-old Simon Fair Timony, then-stepson of Jad Fair, and by Cody Linn Ranaldo, son of Sonic Youth guitarist Lee Ranaldo. After a 7\" single an LP followed in 1995 titled \"A Little Tiny Smelly Bit of...the Stinky Puffs\" and an EP in 1996 titled \"Songs and Advice for Kids Who Have Been Left Behind\".\n",
    "\n",
    "**📗 Hypothesis:**\n",
    "Jad Fair married Simon Fair Timony's mother.\n",
    "\n",
    "**🔍 Prediction Scores:**\n",
    "\n",
    "* Entailment: 0.1%\n",
    "* Neutral: 99.7%\n",
    "* Contradiction: 0.2%\n",
    "\n",
    "**✅ Predicted Label:** neutral\n",
    "**🎯 Gold Label:** entailment\n",
    "\n",
    "**💡 Reasoning:**\n",
    "Jad Fair was Simon Fair Timony's stepfather, so he would have married his mother. Difficult because the mother was never mentioned.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Sample #3\n",
    "\n",
    "**📘 Premise:**\n",
    ".lgbt is a sponsored top-level domain for the LGBT community, sponsored by Afilias. The domain name was delegated to the Root Zone on 18 July 2014. The creation of .lgbt is meant to promote diversity and LGBT businesses, and is open to LGBT businesses, organizations, and anyone wishing to reach the LGBT community.\n",
    "\n",
    "**📗 Hypothesis:**\n",
    "The .lgbt domain is for lgbt small businesses.\n",
    "\n",
    "**🔍 Prediction Scores:**\n",
    "\n",
    "* Entailment: 1.7%\n",
    "* Neutral: 98.0%\n",
    "* Contradiction: 0.2%\n",
    "\n",
    "**✅ Predicted Label:** neutral\n",
    "**🎯 Gold Label:** entailment\n",
    "\n",
    "**💡 Reasoning:**\n",
    "It never directly said if it was for small businesses or all businesses in general.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Sample #4\n",
    "\n",
    "**📘 Premise:**\n",
    "Julian Peter McDonald Clary (born 25 May 1959) is an English comedian and novelist. Openly gay, Clary began appearing on television in the mid-1980s and became known for his deliberately stereotypical camp style. Since then he has also acted in films, television and stage productions, and was the winner of \"Celebrity Big Brother 10\" in 2012.\n",
    "\n",
    "**📗 Hypothesis:**\n",
    "Julian Peter McDonald Clary was less than 30 years old when he began his television career.\n",
    "\n",
    "**🔍 Prediction Scores:**\n",
    "\n",
    "* Entailment: 3.2%\n",
    "* Neutral: 0.8%\n",
    "* Contradiction: 96.0%\n",
    "\n",
    "**✅ Predicted Label:** contradiction\n",
    "**🎯 Gold Label:** entailment\n",
    "\n",
    "**💡 Reasoning:**\n",
    "The statement is true because Clary was around 26 when he started in television. The model was likely confused by vagueness or calculation.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Sample #5\n",
    "\n",
    "**📘 Premise:**\n",
    "The Best of David Bowie 1974/1979 is a compilation album by David Bowie released in 1998. It includes material released between 1974–1979.\n",
    "\n",
    "**📗 Hypothesis:**\n",
    "David Bowie didn't only release an album in 1998 but also in 1979.\n",
    "\n",
    "**🔍 Prediction Scores:**\n",
    "\n",
    "* Entailment: 98.6%\n",
    "* Neutral: 0.7%\n",
    "* Contradiction: 0.7%\n",
    "\n",
    "**✅ Predicted Label:** entailment\n",
    "**🎯 Gold Label:** neutral\n",
    "\n",
    "**💡 Reasoning:**\n",
    "We don't know if he released an album in 1979. Maybe the years confused the system.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Sample #6\n",
    "\n",
    "**📘 Premise:**\n",
    "Gyula Trebitsch (3 November 1914 - 12 December 2005) was a German film producer born in Budapest, Hungary. He was nominated in 1956 for the Academy Award for Best Foreign Language Film along with Walter Koppel for their film \"The Captain of Kopenick\".\n",
    "\n",
    "**📗 Hypothesis:**\n",
    "Gyula Trebitsch was nominated for the Academy Award for Best Foreign Language Film for his work on \"The Captain of Kopenick\" at the age of 43.\n",
    "\n",
    "**🔍 Prediction Scores:**\n",
    "\n",
    "* Entailment: 33.7%\n",
    "* Neutral: 53.0%\n",
    "* Contradiction: 13.3%\n",
    "\n",
    "**✅ Predicted Label:** neutral\n",
    "**🎯 Gold Label:** contradiction\n",
    "\n",
    "**💡 Reasoning:**\n",
    "He was nominated in 1956 and didn't turn 43 until 1957. The system has trouble with ages and birthdays.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Sample #7\n",
    "\n",
    "**📘 Premise:**\n",
    "The Samsung Galaxy Tab 8.9 is an Android-based tablet computer introduced in 2011. It features an 8.9-inch display and a 1 GHz dual-core Nvidia Tegra 2 processor.\n",
    "\n",
    "**📗 Hypothesis:**\n",
    "Samsung Galaxy has about 9 inch display\n",
    "\n",
    "**🔍 Prediction Scores:**\n",
    "\n",
    "* Entailment: 26.9%\n",
    "* Neutral: 15.0%\n",
    "* Contradiction: 58.1%\n",
    "\n",
    "**✅ Predicted Label:** contradiction\n",
    "**🎯 Gold Label:** entailment\n",
    "\n",
    "**💡 Reasoning:**\n",
    "The display is about 8.9 inches, which is approximately 9 inches.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Sample #8\n",
    "\n",
    "**📘 Premise:**\n",
    "\"May the Bird of Paradise Fly Up Your Nose\" is a 1965 novelty song by Little Jimmy Dickens. It was on the chart for a total of 18 weeks.\n",
    "\n",
    "**📗 Hypothesis:**\n",
    "\"May the Bird of Paradise Fly Up Your Nose\" was not on the charts for 6 months\n",
    "\n",
    "**🔍 Prediction Scores:**\n",
    "\n",
    "* Entailment: 10.8%\n",
    "* Neutral: 1.3%\n",
    "* Contradiction: 87.9%\n",
    "\n",
    "**✅ Predicted Label:** contradiction\n",
    "**🎯 Gold Label:** entailment\n",
    "\n",
    "**💡 Reasoning:**\n",
    "18 weeks is less than 6 months. The hypothesis is true.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Sample #9\n",
    "\n",
    "**📘 Premise:**\n",
    "Alexandre \"Xande\" Ribeiro (born January 20, 1981) is a Brazilian Jiu-Jitsu champion.\n",
    "\n",
    "**📗 Hypothesis:**\n",
    "Alexandre \"Xande\" Ribeiro is 38 Years old\n",
    "\n",
    "**🔍 Prediction Scores:**\n",
    "\n",
    "* Entailment: 26.8%\n",
    "* Neutral: 1.2%\n",
    "* Contradiction: 72.0%\n",
    "\n",
    "**✅ Predicted Label:** contradiction\n",
    "**🎯 Gold Label:** entailment\n",
    "\n",
    "**💡 Reasoning:**\n",
    "Using his birthdate and the assumed evaluation year, he would be 38 years old.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Sample #10\n",
    "\n",
    "**📘 Premise:**\n",
    "Bronwen is a Welsh feminine given name introduced to the English-speaking public by a character in the novel \"How Green Was My Valley\" (1939).\n",
    "\n",
    "**📗 Hypothesis:**\n",
    "Bronwen was a named based on a novel\n",
    "\n",
    "**🔍 Prediction Scores:**\n",
    "\n",
    "* Entailment: 5.3%\n",
    "* Neutral: 51.1%\n",
    "* Contradiction: 43.5%\n",
    "\n",
    "**✅ Predicted Label:** neutral\n",
    "**🎯 Gold Label:** entailment\n",
    "\n",
    "**💡 Reasoning:**\n",
    "It was popularized by the novel; this qualifies as being based on it in context.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Sample #11\n",
    "\n",
    "**📘 Premise:**\n",
    "On 10 September 2016, a man attacked another man and later sought to attack police.\n",
    "\n",
    "**📗 Hypothesis:**\n",
    "The perpetrator sought to attack the police from the beginning\n",
    "\n",
    "**🔍 Prediction Scores:**\n",
    "\n",
    "* Entailment: 0.1%\n",
    "* Neutral: 2.4%\n",
    "* Contradiction: 97.5%\n",
    "\n",
    "**✅ Predicted Label:** contradiction\n",
    "**🎯 Gold Label:** neutral\n",
    "\n",
    "**💡 Reasoning:**\n",
    "Text says he sought to attack the police, but doesn't say it was from the beginning.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Sample #12\n",
    "\n",
    "**📘 Premise:**\n",
    "The Panama Canal was completed between 1870–1914. The author David McCullough published a book about it in 1977.\n",
    "\n",
    "**📗 Hypothesis:**\n",
    "The Panama Canal was completed before David McCullough was born.\n",
    "\n",
    "**🔍 Prediction Scores:**\n",
    "\n",
    "* Entailment: 15.0%\n",
    "* Neutral: 1.3%\n",
    "* Contradiction: 83.7%\n",
    "\n",
    "**✅ Predicted Label:** contradiction\n",
    "**🎯 Gold Label:** neutral\n",
    "\n",
    "**💡 Reasoning:**\n",
    "The excerpt doesn’t say when the author was born, so the statement is unconfirmed.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Sample #13\n",
    "\n",
    "**📘 Premise:**\n",
    "\"Anna Sun\" is a song from the 2010 album \"I Want! I Want!\" by Walk the Moon.\n",
    "\n",
    "**📗 Hypothesis:**\n",
    "\"Anna Sun\" is from the 2010 album \"I Want! I Want! I Want!\"\n",
    "\n",
    "**🔍 Prediction Scores:**\n",
    "\n",
    "* Entailment: 73.5%\n",
    "* Neutral: 2.9%\n",
    "* Contradiction: 23.5%\n",
    "\n",
    "**✅ Predicted Label:** entailment\n",
    "**🎯 Gold Label:** contradiction\n",
    "\n",
    "**💡 Reasoning:**\n",
    "Album title is slightly misquoted; it's \"I Want! I Want!\", not triple.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Sample #14\n",
    "\n",
    "**📘 Premise:**\n",
    "Pit bulls can make great companions. Care is needed to properly raise them.\n",
    "\n",
    "**📗 Hypothesis:**\n",
    "Pit Bulls are a cat’s best friend\n",
    "\n",
    "**🔍 Prediction Scores:**\n",
    "\n",
    "* Entailment: 0.0%\n",
    "* Neutral: 0.3%\n",
    "* Contradiction: 99.7%\n",
    "\n",
    "**✅ Predicted Label:** contradiction\n",
    "**🎯 Gold Label:** neutral\n",
    "\n",
    "**💡 Reasoning:**\n",
    "No mention is made of their relationship to cats. Not contradicted, just unsupported.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Sample #15\n",
    "\n",
    "**📘 Premise:**\n",
    "Sandler and Schneider met as struggling comedians in Los Angeles.\n",
    "\n",
    "**📗 Hypothesis:**\n",
    "Comedians in Los Angeles struggle\n",
    "\n",
    "**🔍 Prediction Scores:**\n",
    "\n",
    "* Entailment: 97.8%\n",
    "* Neutral: 2.1%\n",
    "* Contradiction: 0.1%\n",
    "\n",
    "**✅ Predicted Label:** entailment\n",
    "**🎯 Gold Label:** neutral\n",
    "\n",
    "**💡 Reasoning:**\n",
    "This generalization isn't supported; it was just true for two individuals.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Sample #16\n",
    "\n",
    "**📘 Premise:**\n",
    "A customer came into a business, ordered and paid for a drink.\n",
    "\n",
    "**📗 Hypothesis:**\n",
    "The customer is out of money\n",
    "\n",
    "**🔍 Prediction Scores:**\n",
    "\n",
    "* Entailment: 0.1%\n",
    "* Neutral: 5.5%\n",
    "* Contradiction: 94.4%\n",
    "\n",
    "**✅ Predicted Label:** contradiction\n",
    "**🎯 Gold Label:** neutral\n",
    "\n",
    "**💡 Reasoning:**\n",
    "No info on remaining money. Payment doesn’t imply being broke.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Sample #17\n",
    "\n",
    "**📘 Premise:**\n",
    "Section 93 is rooted in 18th-century provisions like the Treaty of Paris (1763).\n",
    "\n",
    "**📗 Hypothesis:**\n",
    "Section 93 gives the details of Treaty of Paris of 1763\n",
    "\n",
    "**🔍 Prediction Scores:**\n",
    "\n",
    "* Entailment: 0.2%\n",
    "* Neutral: 99.4%\n",
    "* Contradiction: 0.4%\n",
    "\n",
    "**✅ Predicted Label:** neutral\n",
    "**🎯 Gold Label:** entailment\n",
    "\n",
    "**💡 Reasoning:**\n",
    "If Section 93 is rooted in the treaty, it entails having its details.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Sample #18\n",
    "\n",
    "**📘 Premise:**\n",
    "Beth sings “Birds in their little nests agree” and resolves an argument.\n",
    "\n",
    "**📗 Hypothesis:**\n",
    "Beth and Jo detest birds in their little nests\n",
    "\n",
    "**🔍 Prediction Scores:**\n",
    "\n",
    "* Entailment: 0.2%\n",
    "* Neutral: 0.5%\n",
    "* Contradiction: 99.3%\n",
    "\n",
    "**✅ Predicted Label:** contradiction\n",
    "**🎯 Gold Label:** neutral\n",
    "\n",
    "**💡 Reasoning:**\n",
    "The quote is metaphorical. There's no evidence about how they feel about birds.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Sample #19\n",
    "\n",
    "**📘 Premise:**\n",
    "ACE Ltd beat analysts’ profit expectations.\n",
    "\n",
    "**📗 Hypothesis:**\n",
    "The analysts were disappointed by the quarterly profits\n",
    "\n",
    "**🔍 Prediction Scores:**\n",
    "\n",
    "* Entailment: 39.6%\n",
    "* Neutral: 56.1%\n",
    "* Contradiction: 4.3%\n",
    "\n",
    "**✅ Predicted Label:** neutral\n",
    "**🎯 Gold Label:** contradiction\n",
    "\n",
    "**💡 Reasoning:**\n",
    "If the company beat expectations, analysts would not be disappointed.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Sample #20\n",
    "\n",
    "**📘 Premise:**\n",
    "Instructions for dressing up a boy like a girl include shaving legs, armpits, and face.\n",
    "\n",
    "**📗 Hypothesis:**\n",
    "Have him take a shower and shave his lower arms, upper back, and face.\n",
    "\n",
    "**🔍 Prediction Scores:**\n",
    "\n",
    "* Entailment: 0.7%\n",
    "* Neutral: 92.4%\n",
    "* Contradiction: 6.9%\n",
    "\n",
    "**✅ Predicted Label:** neutral\n",
    "**🎯 Gold Label:** contradiction\n",
    "\n",
    "**💡 Reasoning:**\n",
    "The specified body parts do not match. Therefore it contradicts the instruction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d35c2935202f5a",
   "metadata": {},
   "source": [
    "### Reasons for the models to fail\n",
    "During our runs, we identify five reasons why the model may fail.\n",
    "#### World-knowledge\n",
    "In some samples, we observed that the model misses facts a human can recall (or look up) instantly.\n",
    "For example, in the first sample, the model treated \"born in NYC\" as *not* evidence of being born in the United States – likely because it fixated on \"…parents from Puerto Rico\" instead of city → country mapping.\n",
    "This was demonstrated in samples 1, 2, 3, 10, and 17.\n",
    "We believe that the model's inference is inconsistent, as explicit city, kinship, or source relations are sometimes overlooked when presented in excessive detail.\n",
    "####  Numerical & date arithmetic\n",
    "In cases where a **sub-second calculation** was needed, the calculation was brittle.\n",
    "For example, in sample number 4, the model needed to calculate that 959 → mid-1980 is approximately 26 years, but instead, it labeled it as a contradiction rather than an entailment.\n",
    "This was shown off in samples 4,5,6,7,8,9.\n",
    "We therefore believe that rounding (\"about 9-inch\", 7) and \"less than/greater than\" comparisons trip it up, off-by-one birthday boundaries (6) are common, and it rarely \"counts months\" (8) or \"years between dates\" (5).\n",
    "#### Scope & quantifier problems\n",
    "We observed that in some samples (for example, 5, 11, 12, 14, 20) there were mistakes where **\"only\", \"all\", \"from the beginning\", \"about\"** changed meaning.\n",
    "For example, in sample 5, the model interprets the presence of any 1974-79 material as evidence of a 1979 release.\n",
    "#### Near-duplicate strings\n",
    "Minor lexical edits or typos mislead the softmax. This was clearly shown in sample 13, where the model didn't seem to differentiate between \"I Want! I Want! **I Want!**\" and \"I Want! I Want!\"\n",
    "#### Pragmatic/commonsense slips\n",
    "In some samples, it was demonstrated that the model lacks common sense beyond explicit text. For example, in sample 19, the model failed causal intuition since \"Beat analysts' estimates\" ⇒ analysts not disappointed (quarterly beats = positive surprise)\n",
    "This was shown in samples 15, 16, 18, and 19."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86305bbe",
   "metadata": {},
   "source": [
    "### Error Observations Table (Task 1.2)\n",
    "\n",
    "| Error Type                  | Description                                                                 | Examples (Sample #s) |\n",
    "|-----------------------------|-----------------------------------------------------------------------------|----------------------|\n",
    "| World-knowledge             | The model misses real-world facts (e.g., city-country mappings or kinship relations) due to fixation on irrelevant details, leading to inconsistent inference. | 1, 2, 3, 10, 17     |\n",
    "| Numerical & date arithmetic | Brittle handling of calculations like ages, durations, or approximations (e.g., off-by-one errors, failure to round or compare dates/quantities). | 4, 5, 6, 7, 8, 9    |\n",
    "| Scope & quantifier problems | Misinterprets qualifiers like \"only\", \"all\", \"from the beginning\", or \"about\", altering the intended scope or meaning. | 5, 11, 12, 14, 20   |\n",
    "| Near-duplicate strings      | Confused by minor lexical changes or typos, treating near-matches as equivalents (e.g., slight title variations). | 13                  |\n",
    "| Pragmatic/commonsense slips | Lacks implicit causal reasoning or common sense beyond explicit text (e.g., implications of \"beating expectations\" or generalizations). | 15, 16, 18, 19      |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
