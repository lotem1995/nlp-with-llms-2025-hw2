{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c468709d",
   "metadata": {},
   "source": [
    "# ImpPres with LLM\n",
    "\n",
    "You have to implement in this notebook a better ImpPres classifier using an LLM.\n",
    "This classifier must be implemented using DSPy.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T07:21:51.913322Z",
     "start_time": "2025-07-30T07:21:39.591497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configure the DSPy environment with the language model - for grok the parameters must be:\n",
    "# env variable should be in os.environ['XAI_API_KEY']\n",
    "# \"xai/grok-3-mini\"\n",
    "import os\n",
    "import dspy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset, Dataset\n",
    "from os.path import exists\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "from typing import Literal\n",
    "from functools import reduce, partial\n",
    "from itertools import chain\n",
    "import evaluate\n",
    "\n",
    "# Configure DSPy\n",
    "lm = dspy.LM('xai/grok-3-mini', api_key=os.environ['XAI_API_KEY'])\n",
    "# for ollama \n",
    "# lm = dspy.LM('ollama_chat/devstral', api_base='http://localhost:11434', api_key='')\n",
    "dspy.configure(lm=lm)\n"
   ],
   "id": "ccdf1a23a9d0f6fc",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Constants and Configuration",
   "id": "723cd5589a5f8ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T07:21:59.798125Z",
     "start_time": "2025-07-30T07:21:51.934754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Global constants to eliminate redundancy\n",
    "SECTIONS = [\n",
    "    'presupposition_all_n_presupposition', \n",
    "    'presupposition_both_presupposition', \n",
    "    'presupposition_change_of_state', \n",
    "    'presupposition_cleft_existence', \n",
    "    'presupposition_cleft_uniqueness', \n",
    "    'presupposition_only_presupposition', \n",
    "    'presupposition_possessed_definites_existence', \n",
    "    'presupposition_possessed_definites_uniqueness', \n",
    "    'presupposition_question_presupposition'\n",
    "]\n",
    "\n",
    "LABEL_NAMES = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "LABEL_TO_ID = {\"entailment\": 0, \"neutral\": 1, \"contradiction\": 2}\n",
    "ID_TO_LABEL = {0: \"entailment\", 1: \"neutral\", 2: \"contradiction\"}\n",
    "\n",
    "# Load evaluation metrics once\n",
    "METRICS = {\n",
    "    'accuracy': evaluate.load(\"accuracy\"),\n",
    "    'precision': evaluate.load(\"precision\"),\n",
    "    'recall': evaluate.load(\"recall\"),\n",
    "    'f1': evaluate.load(\"f1\"),\n",
    "    'combined': evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "}"
   ],
   "id": "b0c006fc884952e5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Functional Utility Functions",
   "id": "5b4af5870ff451c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T07:22:00.209216Z",
     "start_time": "2025-07-30T07:22:00.194787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_or_create_combined_dataset(sections=SECTIONS, parquet_path='combined_imppres_presuppositions.parquet'):\n",
    "    \"\"\"Load combined dataset from parquet or create it from individual sections.\"\"\"\n",
    "    if not exists(parquet_path):\n",
    "        print(\"Creating combined dataset...\")\n",
    "        dataframes = [\n",
    "            load_dataset(\"facebook/imppres\", section).to_pandas().assign(section=section)\n",
    "            for section in sections\n",
    "        ]\n",
    "        combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "        combined_df.to_parquet(parquet_path)\n",
    "        print(f\"Saved combined dataset to {parquet_path}\")\n",
    "    else:\n",
    "        combined_df = pd.read_parquet(parquet_path)\n",
    "        print(f\"Loaded combined dataset from {parquet_path}\")\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "def analyze_paradigm_structure(df):\n",
    "    \"\"\"Analyze and display paradigm structure information.\"\"\"\n",
    "    paradigm_counts = df['paradigmID'].value_counts()\n",
    "    \n",
    "    analysis = {\n",
    "        'total_paradigms': df['paradigmID'].nunique(),\n",
    "        'mean_samples_per_paradigm': paradigm_counts.mean(),\n",
    "        'std_samples_per_paradigm': paradigm_counts.std(),\n",
    "        'paradigm_size_distribution': paradigm_counts.value_counts().head()\n",
    "    }\n",
    "    \n",
    "    # Display analysis\n",
    "    print(\"Paradigm structure analysis:\")\n",
    "    print(f\"Unique paradigm IDs: {analysis['total_paradigms']}\")\n",
    "    print(f\"Samples per paradigm - mean: {analysis['mean_samples_per_paradigm']:.1f}, std: {analysis['std_samples_per_paradigm']:.1f}\")\n",
    "    print(f\"Most common paradigm sizes: {analysis['paradigm_size_distribution']}\")\n",
    "    \n",
    "    # Show example paradigm\n",
    "    first_paradigm_id = df['paradigmID'].iloc[0]\n",
    "    first_paradigm = df[df['paradigmID'] == first_paradigm_id]\n",
    "    print(f\"\\nExample paradigm {first_paradigm_id} ({len(first_paradigm)} samples):\")\n",
    "    print(first_paradigm[['premise', 'hypothesis', 'gold_label']].head())\n",
    "    \n",
    "    return analysis\n"
   ],
   "id": "2b359bff2287719c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 2.4: Explanation CoT LLM for ImpPres and Consistency Validation\n",
    "\n",
    "This implementation improves presupposition identification by exploiting paradigm signals in the ImpPres dataset.\n",
    "We use consistency across paradigms as a reward measure during LLM optimization, combined with overall accuracy.\n"
   ],
   "id": "ab5762c89f472f23"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T07:22:00.309458Z",
     "start_time": "2025-07-30T07:22:00.243906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load and analyze the combined dataset\n",
    "combined_df = load_or_create_combined_dataset()\n",
    "print(f\"Combined dataset shape: {combined_df.shape}\")\n",
    "print(f\"Columns: {combined_df.columns.tolist()}\")\n",
    "\n",
    "paradigm_analysis = analyze_paradigm_structure(combined_df)\n"
   ],
   "id": "b1ffa93e84d35c87",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded combined dataset from combined_imppres_presuppositions.parquet\n",
      "Combined dataset shape: (17100, 11)\n",
      "Columns: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID', 'section']\n",
      "Paradigm structure analysis:\n",
      "Unique paradigm IDs: 100\n",
      "Samples per paradigm - mean: 171.0, std: 0.0\n",
      "Most common paradigm sizes: count\n",
      "171    100\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Example paradigm 0 (171 samples):\n",
      "                                             premise  \\\n",
      "0  All ten guys that proved to boast were divorcing.   \n",
      "1  All ten guys that proved to boast were divorcing.   \n",
      "2  All ten guys that proved to boast were divorcing.   \n",
      "3  All ten guys that proved to boast weren't divo...   \n",
      "4  All ten guys that proved to boast weren't divo...   \n",
      "\n",
      "                                          hypothesis  gold_label  \n",
      "0   There are exactly ten guys that proved to boast.           0  \n",
      "1  There are exactly eleven guys that proved to b...           2  \n",
      "2  There are exactly ten senators that proved to ...           1  \n",
      "3   There are exactly ten guys that proved to boast.           0  \n",
      "4  There are exactly eleven guys that proved to b...           2  \n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### DSPy Signature for Explanation-based Classification\n",
   "id": "5ca35ca6c07bdb61"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T07:22:00.504228Z",
     "start_time": "2025-07-30T07:22:00.494217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ExplanationNLIClassifier(dspy.Signature):\n",
    "    \"\"\"Classify premise-hypothesis pairs with explanations for presupposition identification.\"\"\"\n",
    "    \n",
    "    premise: str = dspy.InputField(desc=\"A short passage or statement containing potential presuppositions.\")\n",
    "    hypothesis: str = dspy.InputField(desc=\"A statement to evaluate against the premise for presupposition relationships.\")\n",
    "    \n",
    "    explanation: str = dspy.OutputField(desc=\"Provide a detailed explanation of the presupposition relationship between the premise and hypothesis. Explain what presuppositions are triggered and how they relate to the entailment.\")\n",
    "    \n",
    "    label: Literal[\"entailment\", \"neutral\", \"contradiction\"] = dspy.OutputField(\n",
    "        desc=(\n",
    "            \"Based on the presupposition analysis, classify as:\\n\"\n",
    "            \"- 'entailment': The hypothesis follows from the premise's presuppositions\\n\"\n",
    "            \"- 'contradiction': The hypothesis contradicts the premise's presuppositions\\n\"\n",
    "            \"- 'neutral': The hypothesis is unrelated to the premise's presuppositions\"\n",
    "        )\n",
    "    )\n"
   ],
   "id": "fe62b52296fe9bf2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Functional Paradigm Consistency Functions\n",
   "id": "a52b24528fda18be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T07:22:00.672487Z",
     "start_time": "2025-07-30T07:22:00.653953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def group_by_paradigm(df):\n",
    "    \"\"\"Group samples by paradigmID\"\"\"\n",
    "    return df.groupby('paradigmID')\n",
    "\n",
    "def calculate_paradigm_consistency(paradigm_groups, predictions_dict):\n",
    "    \"\"\"Calculate consistency score for each paradigm\"\"\"\n",
    "    consistency_scores = {}\n",
    "    \n",
    "    for paradigm_id, group in paradigm_groups:\n",
    "        if len(group) < 2:  # Skip paradigms with only one sample\n",
    "            continue\n",
    "            \n",
    "        # Get predictions for this paradigm\n",
    "        paradigm_preds = [\n",
    "            predictions_dict[idx] for idx in group.index \n",
    "            if idx in predictions_dict\n",
    "        ]\n",
    "        \n",
    "        if len(paradigm_preds) < 2:\n",
    "            continue\n",
    "        \n",
    "        # Calculate consistency as agreement rate\n",
    "        pred_labels = [pred['pred_label'] for pred in paradigm_preds]\n",
    "        label_counts = Counter(pred_labels)\n",
    "        most_common_count = label_counts.most_common(1)[0][1]\n",
    "        consistency = most_common_count / len(pred_labels)\n",
    "        \n",
    "        consistency_scores[paradigm_id] = {\n",
    "            'consistency': consistency,\n",
    "            'size': len(paradigm_preds),\n",
    "            'predictions': pred_labels\n",
    "        }\n",
    "    \n",
    "    return consistency_scores\n",
    "\n",
    "def calculate_overall_consistency(consistency_scores):\n",
    "    \"\"\"Calculate overall consistency across all paradigms\"\"\"\n",
    "    if not consistency_scores:\n",
    "        return 0.0\n",
    "    \n",
    "    total_weighted_consistency = sum(\n",
    "        scores['consistency'] * scores['size'] \n",
    "        for scores in consistency_scores.values()\n",
    "    )\n",
    "    total_samples = sum(scores['size'] for scores in consistency_scores.values())\n",
    "    \n",
    "    return total_weighted_consistency / total_samples if total_samples > 0 else 0.0\n",
    "\n",
    "def calculate_accuracy(predictions_dict, gold_labels_dict):\n",
    "    \"\"\"Calculate accuracy using evaluate library\"\"\"\n",
    "    # Convert predictions and references to the format expected by evaluate library\n",
    "    valid_indices = [idx for idx in predictions_dict.keys() if idx in gold_labels_dict]\n",
    "    \n",
    "    if not valid_indices:\n",
    "        return 0.0\n",
    "    \n",
    "    # Extract predictions and references in aligned order\n",
    "    preds = [LABEL_TO_ID[predictions_dict[idx]['pred_label']] for idx in valid_indices]\n",
    "    refs = [LABEL_TO_ID[gold_labels_dict[idx]] for idx in valid_indices]\n",
    "    \n",
    "    # Use evaluate library for accuracy calculation\n",
    "    return METRICS['accuracy'].compute(predictions=preds, references=refs)['accuracy']\n",
    "\n",
    "def calculate_combined_score(predictions_dict, gold_labels_dict, paradigm_groups, alpha=0.7):\n",
    "    \"\"\"Calculate combined score of accuracy and consistency\"\"\"\n",
    "    accuracy = calculate_accuracy(predictions_dict, gold_labels_dict)\n",
    "    consistency_scores = calculate_paradigm_consistency(paradigm_groups, predictions_dict)\n",
    "    overall_consistency = calculate_overall_consistency(consistency_scores)\n",
    "    \n",
    "    combined_score = alpha * accuracy + (1 - alpha) * overall_consistency\n",
    "    \n",
    "    return {\n",
    "        'combined_score': combined_score,\n",
    "        'accuracy': accuracy,\n",
    "        'consistency': overall_consistency,\n",
    "        'paradigm_scores': consistency_scores\n",
    "    }"
   ],
   "id": "85bffe152dd7f808",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Functional DSPy Predictor\n",
   "id": "938ef58d77b2171b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T07:22:00.799022Z",
     "start_time": "2025-07-30T07:22:00.788516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_explanation_predictor():\n",
    "    \"\"\"Create explanation predictor\"\"\"\n",
    "    return dspy.Predict(ExplanationNLIClassifier)\n",
    "\n",
    "def predict_with_explanation(predictor, premise, hypothesis):\n",
    "    \"\"\"Make prediction with explanation\"\"\"\n",
    "    result = predictor(premise=premise, hypothesis=hypothesis)\n",
    "    return {\n",
    "        'explanation': result.explanation,\n",
    "        'label': result.label\n",
    "    }\n",
    "\n",
    "# Initialize the predictor\n",
    "explanation_predictor = create_explanation_predictor()\n"
   ],
   "id": "cb6b95842069afde",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Functional Evaluation Functions\n",
   "id": "3cabc124bb9c6048"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T07:22:00.891684Z",
     "start_time": "2025-07-30T07:22:00.878377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_example(predictor, example, section_name, index):\n",
    "    \"\"\"Process a single example\"\"\"\n",
    "    try:\n",
    "        pred_result = predict_with_explanation(\n",
    "            predictor, \n",
    "            example['premise'], \n",
    "            example['hypothesis']\n",
    "        )\n",
    "        \n",
    "        gold_label = ID_TO_LABEL[example['gold_label']]\n",
    "        \n",
    "        result = {\n",
    "            'premise': example['premise'],\n",
    "            'hypothesis': example['hypothesis'],\n",
    "            'explanation': pred_result['explanation'],\n",
    "            'pred_label': pred_result['label'],\n",
    "            'gold_label': gold_label,\n",
    "            'paradigmID': example.get('paradigmID', ''),\n",
    "            'UID': example.get('UID', ''),\n",
    "            'section': section_name\n",
    "        }\n",
    "        \n",
    "        return result, (index, result), (index, gold_label)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing example {index}: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "def evaluate_section(predictor, dataset_section, section_name, max_samples=None):\n",
    "    \"\"\"Evaluate predictor on a dataset section\"\"\"\n",
    "    print(f\"Evaluating section: {section_name}\")\n",
    "    \n",
    "    # Convert to list for easier handling\n",
    "    data_list = (list(dataset_section) if isinstance(dataset_section, Dataset) \n",
    "                else dataset_section.to_dict('records'))\n",
    "    \n",
    "    if max_samples:\n",
    "        data_list = data_list[:max_samples]\n",
    "    \n",
    "    # Process all examples\n",
    "    processed = [\n",
    "        process_example(predictor, example, section_name, i)\n",
    "        for i, example in enumerate(tqdm(data_list, desc=f\"Processing {section_name}\"))\n",
    "    ]\n",
    "    \n",
    "    # Filter out failed examples and separate results\n",
    "    valid_results = [item for item in processed if item[0] is not None]\n",
    "    \n",
    "    if not valid_results:\n",
    "        return [], {}, {}\n",
    "    \n",
    "    results, predictions_items, gold_items = zip(*valid_results)\n",
    "    predictions_dict = dict(predictions_items)\n",
    "    gold_labels_dict = dict(gold_items)\n",
    "    \n",
    "    return list(results), predictions_dict, gold_labels_dict\n",
    "\n",
    "def create_section_datasets(combined_df, sections=SECTIONS):\n",
    "    \"\"\"Create section datasets from combined dataframe\"\"\"\n",
    "    return {\n",
    "        section: Dataset.from_pandas(combined_df[combined_df['section'] == section])\n",
    "        for section in sections\n",
    "    }\n"
   ],
   "id": "f130d9e3e55632a",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Run Evaluation on All Sections\n",
   "id": "65e1bf3d682de1f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:03:26.802904Z",
     "start_time": "2025-07-30T07:22:00.952884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get paradigm groups for consistency calculation\n",
    "paradigm_groups = group_by_paradigm(combined_df)\n",
    "\n",
    "# Create section datasets\n",
    "section_datasets = create_section_datasets(combined_df)\n",
    "\n",
    "# Evaluate each section with limited samples for cost control\n",
    "max_samples_per_section = 50  # Adjust based on budget\n",
    "\n",
    "# Functional evaluation pipeline\n",
    "evaluation_results = {\n",
    "    section_name: evaluate_section(\n",
    "        explanation_predictor, \n",
    "        section_datasets[section_name], \n",
    "        section_name, \n",
    "        max_samples_per_section\n",
    "    )\n",
    "    for section_name in SECTIONS\n",
    "}\n",
    "\n",
    "# Separate results for analysis\n",
    "all_results = {name: results[0] for name, results in evaluation_results.items()}\n",
    "all_predictions = dict(chain.from_iterable(\n",
    "    results[1].items() for results in evaluation_results.values()\n",
    "))\n",
    "all_gold_labels = dict(chain.from_iterable(\n",
    "    results[2].items() for results in evaluation_results.values()\n",
    "))\n"
   ],
   "id": "e5b8db61edb9ce41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating section: presupposition_all_n_presupposition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing presupposition_all_n_presupposition: 100%|██████████| 50/50 [04:24<00:00,  5.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating section: presupposition_both_presupposition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing presupposition_both_presupposition: 100%|██████████| 50/50 [03:51<00:00,  4.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating section: presupposition_change_of_state\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing presupposition_change_of_state: 100%|██████████| 50/50 [05:27<00:00,  6.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating section: presupposition_cleft_existence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing presupposition_cleft_existence: 100%|██████████| 50/50 [04:09<00:00,  4.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating section: presupposition_cleft_uniqueness\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing presupposition_cleft_uniqueness: 100%|██████████| 50/50 [05:15<00:00,  6.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating section: presupposition_only_presupposition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing presupposition_only_presupposition: 100%|██████████| 50/50 [04:36<00:00,  5.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating section: presupposition_possessed_definites_existence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing presupposition_possessed_definites_existence: 100%|██████████| 50/50 [03:56<00:00,  4.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating section: presupposition_possessed_definites_uniqueness\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing presupposition_possessed_definites_uniqueness: 100%|██████████| 50/50 [05:40<00:00,  6.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating section: presupposition_question_presupposition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing presupposition_question_presupposition: 100%|██████████| 50/50 [04:01<00:00,  4.83s/it]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Functional Results Analysis and Metrics Computation\n",
   "id": "7bb50817d37c212f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:03:26.891725Z",
     "start_time": "2025-07-30T08:03:26.882970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_section_metrics(section_results, paradigm_groups):\n",
    "    \"\"\"Compute metrics for a section\"\"\"\n",
    "    if not section_results:\n",
    "        return None\n",
    "    \n",
    "    # Convert labels to IDs for metrics computation\n",
    "    preds = [LABEL_TO_ID[result['pred_label']] for result in section_results]\n",
    "    refs = [LABEL_TO_ID[result['gold_label']] for result in section_results]\n",
    "    \n",
    "    # Calculate standard classification metrics\n",
    "    metrics = {\n",
    "        'accuracy': METRICS['accuracy'].compute(predictions=preds, references=refs)['accuracy'],\n",
    "        'precision': METRICS['precision'].compute(predictions=preds, references=refs, average='weighted')['precision'],\n",
    "        'recall': METRICS['recall'].compute(predictions=preds, references=refs, average='weighted')['recall'],\n",
    "        'f1': METRICS['f1'].compute(predictions=preds, references=refs, average='weighted')['f1'],\n",
    "        'samples': len(section_results)\n",
    "    }\n",
    "    \n",
    "    # Calculate section-specific consistency\n",
    "    section_predictions = {i: result for i, result in enumerate(section_results)}\n",
    "    section_gold = {i: result['gold_label'] for i, result in enumerate(section_results)}\n",
    "    section_combined = calculate_combined_score(section_predictions, section_gold, paradigm_groups)\n",
    "    \n",
    "    metrics.update({\n",
    "        'consistency': section_combined['consistency'],\n",
    "        'combined_score': section_combined['combined_score']\n",
    "    })\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def print_section_metrics(section_name, metrics):\n",
    "    \"\"\"Print section metrics - pure function for display.\"\"\"\n",
    "    print(f\"\\n{section_name}:\")\n",
    "    print(f\"  Samples: {metrics['samples']}\")\n",
    "    print(f\"  Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"  Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"  Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"  F1: {metrics['f1']:.4f}\")\n",
    "    print(f\"  Consistency: {metrics['consistency']:.4f}\")\n",
    "    print(f\"  Combined Score: {metrics['combined_score']:.4f}\")\n"
   ],
   "id": "8731b52c3ee9703a",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:03:27.118163Z",
     "start_time": "2025-07-30T08:03:27.091958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate overall metrics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OVERALL RESULTS ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "overall_metrics = calculate_combined_score(all_predictions, all_gold_labels, paradigm_groups)\n",
    "\n",
    "print(f\"Overall Accuracy: {overall_metrics['accuracy']:.4f}\")\n",
    "print(f\"Overall Consistency: {overall_metrics['consistency']:.4f}\")\n",
    "print(f\"Combined Score: {overall_metrics['combined_score']:.4f}\")\n"
   ],
   "id": "944081fdd33f048d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "OVERALL RESULTS ANALYSIS\n",
      "============================================================\n",
      "Overall Accuracy: 1.0000\n",
      "Overall Consistency: 0.4000\n",
      "Combined Score: 0.8200\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:03:27.478251Z",
     "start_time": "2025-07-30T08:03:27.190554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate metrics per section\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SECTION-WISE PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "section_metrics = {}\n",
    "for section_name in SECTIONS:\n",
    "    if section_name in all_results:\n",
    "        metrics = compute_section_metrics(all_results[section_name], paradigm_groups)\n",
    "        if metrics:\n",
    "            section_metrics[section_name] = metrics\n",
    "            print_section_metrics(section_name, metrics)\n"
   ],
   "id": "78b37e3eb946c211",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SECTION-WISE PERFORMANCE\n",
      "============================================================\n",
      "\n",
      "presupposition_all_n_presupposition:\n",
      "  Samples: 50\n",
      "  Accuracy: 0.9800\n",
      "  Precision: 0.9810\n",
      "  Recall: 0.9800\n",
      "  F1: 0.9799\n",
      "  Consistency: 0.4200\n",
      "  Combined Score: 0.8120\n",
      "\n",
      "presupposition_both_presupposition:\n",
      "  Samples: 50\n",
      "  Accuracy: 0.9400\n",
      "  Precision: 0.9478\n",
      "  Recall: 0.9400\n",
      "  F1: 0.9390\n",
      "  Consistency: 0.4600\n",
      "  Combined Score: 0.7960\n",
      "\n",
      "presupposition_change_of_state:\n",
      "  Samples: 50\n",
      "  Accuracy: 0.8800\n",
      "  Precision: 0.8812\n",
      "  Recall: 0.8800\n",
      "  F1: 0.8792\n",
      "  Consistency: 0.4400\n",
      "  Combined Score: 0.7480\n",
      "\n",
      "presupposition_cleft_existence:\n",
      "  Samples: 50\n",
      "  Accuracy: 0.9800\n",
      "  Precision: 0.9810\n",
      "  Recall: 0.9800\n",
      "  F1: 0.9799\n",
      "  Consistency: 0.4200\n",
      "  Combined Score: 0.8120\n",
      "\n",
      "presupposition_cleft_uniqueness:\n",
      "  Samples: 50\n",
      "  Accuracy: 0.3600\n",
      "  Precision: 0.1500\n",
      "  Recall: 0.3600\n",
      "  F1: 0.2118\n",
      "  Consistency: 0.9600\n",
      "  Combined Score: 0.5400\n",
      "\n",
      "presupposition_only_presupposition:\n",
      "  Samples: 50\n",
      "  Accuracy: 0.8400\n",
      "  Precision: 0.8677\n",
      "  Recall: 0.8400\n",
      "  F1: 0.8417\n",
      "  Consistency: 0.5200\n",
      "  Combined Score: 0.7440\n",
      "\n",
      "presupposition_possessed_definites_existence:\n",
      "  Samples: 50\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall: 1.0000\n",
      "  F1: 1.0000\n",
      "  Consistency: 0.4000\n",
      "  Combined Score: 0.8200\n",
      "\n",
      "presupposition_possessed_definites_uniqueness:\n",
      "  Samples: 50\n",
      "  Accuracy: 0.5600\n",
      "  Precision: 0.7905\n",
      "  Recall: 0.5600\n",
      "  F1: 0.5093\n",
      "  Consistency: 0.8400\n",
      "  Combined Score: 0.6440\n",
      "\n",
      "presupposition_question_presupposition:\n",
      "  Samples: 50\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall: 1.0000\n",
      "  F1: 1.0000\n",
      "  Consistency: 0.4000\n",
      "  Combined Score: 0.8200\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:03:27.520712Z",
     "start_time": "2025-07-30T08:03:27.493492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create results summary table\n",
    "results_df = pd.DataFrame.from_dict(section_metrics, orient='index')\n",
    "results_df = results_df.round(4)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY TABLE\")\n",
    "print(\"=\"*60)\n",
    "display(results_df)"
   ],
   "id": "3268a8708a370f1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUMMARY TABLE\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                               accuracy  precision  recall  \\\n",
       "presupposition_all_n_presupposition                0.98     0.9810    0.98   \n",
       "presupposition_both_presupposition                 0.94     0.9478    0.94   \n",
       "presupposition_change_of_state                     0.88     0.8812    0.88   \n",
       "presupposition_cleft_existence                     0.98     0.9810    0.98   \n",
       "presupposition_cleft_uniqueness                    0.36     0.1500    0.36   \n",
       "presupposition_only_presupposition                 0.84     0.8677    0.84   \n",
       "presupposition_possessed_definites_existence       1.00     1.0000    1.00   \n",
       "presupposition_possessed_definites_uniqueness      0.56     0.7905    0.56   \n",
       "presupposition_question_presupposition             1.00     1.0000    1.00   \n",
       "\n",
       "                                                   f1  samples  consistency  \\\n",
       "presupposition_all_n_presupposition            0.9799       50         0.42   \n",
       "presupposition_both_presupposition             0.9390       50         0.46   \n",
       "presupposition_change_of_state                 0.8792       50         0.44   \n",
       "presupposition_cleft_existence                 0.9799       50         0.42   \n",
       "presupposition_cleft_uniqueness                0.2118       50         0.96   \n",
       "presupposition_only_presupposition             0.8417       50         0.52   \n",
       "presupposition_possessed_definites_existence   1.0000       50         0.40   \n",
       "presupposition_possessed_definites_uniqueness  0.5093       50         0.84   \n",
       "presupposition_question_presupposition         1.0000       50         0.40   \n",
       "\n",
       "                                               combined_score  \n",
       "presupposition_all_n_presupposition                     0.812  \n",
       "presupposition_both_presupposition                      0.796  \n",
       "presupposition_change_of_state                          0.748  \n",
       "presupposition_cleft_existence                          0.812  \n",
       "presupposition_cleft_uniqueness                         0.540  \n",
       "presupposition_only_presupposition                      0.744  \n",
       "presupposition_possessed_definites_existence            0.820  \n",
       "presupposition_possessed_definites_uniqueness           0.644  \n",
       "presupposition_question_presupposition                  0.820  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>samples</th>\n",
       "      <th>consistency</th>\n",
       "      <th>combined_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>presupposition_all_n_presupposition</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.9810</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.9799</td>\n",
       "      <td>50</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presupposition_both_presupposition</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.9478</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.9390</td>\n",
       "      <td>50</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presupposition_change_of_state</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.8812</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.8792</td>\n",
       "      <td>50</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presupposition_cleft_existence</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.9810</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.9799</td>\n",
       "      <td>50</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presupposition_cleft_uniqueness</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.2118</td>\n",
       "      <td>50</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presupposition_only_presupposition</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.8677</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.8417</td>\n",
       "      <td>50</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presupposition_possessed_definites_existence</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>50</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presupposition_possessed_definites_uniqueness</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.7905</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.5093</td>\n",
       "      <td>50</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presupposition_question_presupposition</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>50</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Functional Analysis Utilities\n",
   "id": "6a28d1e877a8e8ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:03:27.791088Z",
     "start_time": "2025-07-30T08:03:27.782132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def analyze_consistency_distribution(paradigm_scores):\n",
    "    \"\"\"Analyze consistency distribution\"\"\"\n",
    "    if not paradigm_scores:\n",
    "        return {}\n",
    "    \n",
    "    consistency_values = [scores['consistency'] for scores in paradigm_scores.values()]\n",
    "    return {\n",
    "        'mean': np.mean(consistency_values),\n",
    "        'std': np.std(consistency_values),\n",
    "        'min': np.min(consistency_values),\n",
    "        'max': np.max(consistency_values),\n",
    "        'total_paradigms': len(paradigm_scores)\n",
    "    }\n",
    "\n",
    "def get_top_paradigms(paradigm_scores, n=5, reverse=True):\n",
    "    \"\"\"Get top N paradigms by consistency\"\"\"\n",
    "    if not paradigm_scores:\n",
    "        return []\n",
    "    \n",
    "    sorted_paradigms = sorted(\n",
    "        paradigm_scores.items(), \n",
    "        key=lambda x: x[1]['consistency'], \n",
    "        reverse=reverse\n",
    "    )\n",
    "    return sorted_paradigms[:n]\n",
    "\n",
    "def group_results_by_paradigm(all_results):\n",
    "    \"\"\"Group results by paradigm ID\"\"\"\n",
    "    paradigm_analysis = defaultdict(list)\n",
    "    \n",
    "    for section_name, section_results in all_results.items():\n",
    "        for result in section_results:\n",
    "            paradigm_id = result.get('paradigmID', '')\n",
    "            if paradigm_id:\n",
    "                paradigm_analysis[paradigm_id].append({\n",
    "                    'section': section_name,\n",
    "                    'pred_label': result['pred_label'],\n",
    "                    'gold_label': result['gold_label'],\n",
    "                    'correct': result['pred_label'] == result['gold_label']\n",
    "                })\n",
    "    \n",
    "    return paradigm_analysis\n",
    "\n",
    "def analyze_transformation_patterns(paradigm_analysis):\n",
    "    \"\"\"Analyze transformation patterns\"\"\"\n",
    "    transformation_patterns = defaultdict(int)\n",
    "    correct_by_position = defaultdict(list)\n",
    "    \n",
    "    for paradigm_id, paradigm_results in paradigm_analysis.items():\n",
    "        if len(paradigm_results) > 1:  # Only analyze paradigms with multiple samples\n",
    "            # Count correct predictions by position in paradigm\n",
    "            for i, result in enumerate(paradigm_results):\n",
    "                correct_by_position[i].append(result['correct'])\n",
    "                \n",
    "            # Analyze transformation patterns\n",
    "            labels = [r['pred_label'] for r in paradigm_results]\n",
    "            pattern = tuple(labels)\n",
    "            transformation_patterns[pattern] += 1\n",
    "    \n",
    "    return transformation_patterns, correct_by_position\n",
    "\n",
    "def get_example_predictions(all_results, max_examples=5, examples_per_section=2):\n",
    "    \"\"\"Get example predictions\"\"\"\n",
    "    examples = []\n",
    "    example_count = 0\n",
    "    \n",
    "    for section_name, section_results in all_results.items():\n",
    "        if example_count >= max_examples:\n",
    "            break\n",
    "            \n",
    "        section_examples = section_results[:examples_per_section]\n",
    "        for result in section_examples:\n",
    "            if example_count >= max_examples:\n",
    "                break\n",
    "                \n",
    "            examples.append({\n",
    "                'section': section_name,\n",
    "                'premise': result['premise'],\n",
    "                'hypothesis': result['hypothesis'],\n",
    "                'explanation': result['explanation'],\n",
    "                'pred_label': result['pred_label'],\n",
    "                'gold_label': result['gold_label'],\n",
    "                'correct': result['pred_label'] == result['gold_label']\n",
    "            })\n",
    "            example_count += 1\n",
    "    \n",
    "    return examples\n",
    "\n",
    "def print_header(title, width=60):\n",
    "    \"\"\"Print formatted header\"\"\"\n",
    "    print(\"\\n\" + \"=\"*width)\n",
    "    print(title)\n",
    "    print(\"=\"*width)"
   ],
   "id": "cefd9fd2fbc2d496",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Functional Paradigm Analysis\n",
   "id": "14fbc8cd3003f07c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:03:27.967820Z",
     "start_time": "2025-07-30T08:03:27.961271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Analyze paradigm consistency\n",
    "print_header(\"PARADIGM CONSISTENCY ANALYSIS\")\n",
    "\n",
    "paradigm_scores = overall_metrics['paradigm_scores']\n",
    "consistency_stats = analyze_consistency_distribution(paradigm_scores)\n",
    "\n",
    "print(f\"Total paradigms analyzed: {consistency_stats['total_paradigms']}\")\n",
    "if consistency_stats:\n",
    "    print(f\"Mean paradigm consistency: {consistency_stats['mean']:.4f}\")\n",
    "    print(f\"Std paradigm consistency: {consistency_stats['std']:.4f}\")\n",
    "    print(f\"Min paradigm consistency: {consistency_stats['min']:.4f}\")\n",
    "    print(f\"Max paradigm consistency: {consistency_stats['max']:.4f}\")\n",
    "\n",
    "# Show examples of high and low consistency paradigms\n",
    "most_consistent = get_top_paradigms(paradigm_scores, n=5, reverse=True)\n",
    "least_consistent = get_top_paradigms(paradigm_scores, n=5, reverse=False)\n",
    "\n",
    "if most_consistent:\n",
    "    print(f\"\\nTop 5 most consistent paradigms:\")\n",
    "    for i, (paradigm_id, scores) in enumerate(most_consistent):\n",
    "        print(f\"  {i+1}. Paradigm {paradigm_id}: {scores['consistency']:.4f} (size: {scores['size']})\")\n",
    "        print(f\"     Predictions: {scores['predictions']}\")\n",
    "\n",
    "if least_consistent:\n",
    "    print(f\"\\nTop 5 least consistent paradigms:\")\n",
    "    for i, (paradigm_id, scores) in enumerate(least_consistent):\n",
    "        print(f\"  {i+1}. Paradigm {paradigm_id}: {scores['consistency']:.4f} (size: {scores['size']})\")\n",
    "        print(f\"     Predictions: {scores['predictions']}\")"
   ],
   "id": "974a74404a8e6a83",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PARADIGM CONSISTENCY ANALYSIS\n",
      "============================================================\n",
      "Total paradigms analyzed: 3\n",
      "Mean paradigm consistency: 0.3918\n",
      "Std paradigm consistency: 0.0414\n",
      "Min paradigm consistency: 0.3333\n",
      "Max paradigm consistency: 0.4211\n",
      "\n",
      "Top 5 most consistent paradigms:\n",
      "  1. Paradigm 0: 0.4211 (size: 19)\n",
      "     Predictions: ['entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral']\n",
      "  2. Paradigm 1: 0.4211 (size: 19)\n",
      "     Predictions: ['entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral']\n",
      "  3. Paradigm 2: 0.3333 (size: 12)\n",
      "     Predictions: ['entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral']\n",
      "\n",
      "Top 5 least consistent paradigms:\n",
      "  1. Paradigm 2: 0.3333 (size: 12)\n",
      "     Predictions: ['entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral']\n",
      "  2. Paradigm 0: 0.4211 (size: 19)\n",
      "     Predictions: ['entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral']\n",
      "  3. Paradigm 1: 0.4211 (size: 19)\n",
      "     Predictions: ['entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral']\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Functional Transformation Analysis\n",
   "id": "6388ed7001b4fdf4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:03:28.039672Z",
     "start_time": "2025-07-30T08:03:28.031143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Analyze transformation patterns\n",
    "print_header(\"TRANSFORMATION TYPE ANALYSIS\")\n",
    "\n",
    "paradigm_analysis = group_results_by_paradigm(all_results)\n",
    "transformation_patterns, correct_by_position = analyze_transformation_patterns(paradigm_analysis)\n",
    "\n",
    "print(f\"Most common prediction patterns across paradigms:\")\n",
    "sorted_patterns = sorted(transformation_patterns.items(), key=lambda x: x[1], reverse=True)\n",
    "for i, (pattern, count) in enumerate(sorted_patterns[:10]):\n",
    "    print(f\"  {i+1}. {pattern}: {count} paradigms\")\n",
    "\n",
    "print(f\"\\nAccuracy by transformation position:\")\n",
    "for pos, correct_list in correct_by_position.items():\n",
    "    if correct_list:\n",
    "        pos_accuracy = np.mean(correct_list)\n",
    "        print(f\"  Position {pos}: {pos_accuracy:.4f} ({len(correct_list)} samples)\")"
   ],
   "id": "a2173a16f400f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRANSFORMATION TYPE ANALYSIS\n",
      "============================================================\n",
      "Most common prediction patterns across paradigms:\n",
      "  1. ('entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'neutral', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'entailment', 'neutral', 'neutral', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'contradiction', 'neutral', 'neutral', 'neutral'): 1 paradigms\n",
      "  2. ('entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'contradiction', 'entailment', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'contradiction', 'contradiction', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'neutral', 'neutral', 'neutral', 'entailment', 'contradiction', 'neutral', 'neutral', 'contradiction', 'neutral', 'entailment', 'neutral', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral', 'entailment', 'contradiction', 'neutral'): 1 paradigms\n",
      "\n",
      "Accuracy by transformation position:\n",
      "  Position 0: 1.0000 (2 samples)\n",
      "  Position 1: 1.0000 (2 samples)\n",
      "  Position 2: 1.0000 (2 samples)\n",
      "  Position 3: 1.0000 (2 samples)\n",
      "  Position 4: 1.0000 (2 samples)\n",
      "  Position 5: 1.0000 (2 samples)\n",
      "  Position 6: 1.0000 (2 samples)\n",
      "  Position 7: 1.0000 (2 samples)\n",
      "  Position 8: 1.0000 (2 samples)\n",
      "  Position 9: 1.0000 (2 samples)\n",
      "  Position 10: 1.0000 (2 samples)\n",
      "  Position 11: 1.0000 (2 samples)\n",
      "  Position 12: 1.0000 (2 samples)\n",
      "  Position 13: 1.0000 (2 samples)\n",
      "  Position 14: 1.0000 (2 samples)\n",
      "  Position 15: 1.0000 (2 samples)\n",
      "  Position 16: 1.0000 (2 samples)\n",
      "  Position 17: 1.0000 (2 samples)\n",
      "  Position 18: 1.0000 (2 samples)\n",
      "  Position 19: 1.0000 (2 samples)\n",
      "  Position 20: 1.0000 (2 samples)\n",
      "  Position 21: 1.0000 (2 samples)\n",
      "  Position 22: 1.0000 (2 samples)\n",
      "  Position 23: 1.0000 (2 samples)\n",
      "  Position 24: 0.5000 (2 samples)\n",
      "  Position 25: 0.5000 (2 samples)\n",
      "  Position 26: 1.0000 (2 samples)\n",
      "  Position 27: 1.0000 (2 samples)\n",
      "  Position 28: 1.0000 (2 samples)\n",
      "  Position 29: 1.0000 (2 samples)\n",
      "  Position 30: 1.0000 (2 samples)\n",
      "  Position 31: 1.0000 (2 samples)\n",
      "  Position 32: 1.0000 (2 samples)\n",
      "  Position 33: 1.0000 (2 samples)\n",
      "  Position 34: 0.5000 (2 samples)\n",
      "  Position 35: 1.0000 (2 samples)\n",
      "  Position 36: 1.0000 (2 samples)\n",
      "  Position 37: 1.0000 (2 samples)\n",
      "  Position 38: 1.0000 (2 samples)\n",
      "  Position 39: 1.0000 (2 samples)\n",
      "  Position 40: 1.0000 (2 samples)\n",
      "  Position 41: 1.0000 (2 samples)\n",
      "  Position 42: 1.0000 (2 samples)\n",
      "  Position 43: 1.0000 (2 samples)\n",
      "  Position 44: 1.0000 (2 samples)\n",
      "  Position 45: 1.0000 (2 samples)\n",
      "  Position 46: 1.0000 (2 samples)\n",
      "  Position 47: 1.0000 (2 samples)\n",
      "  Position 48: 0.5000 (2 samples)\n",
      "  Position 49: 0.5000 (2 samples)\n",
      "  Position 50: 1.0000 (2 samples)\n",
      "  Position 51: 0.5000 (2 samples)\n",
      "  Position 52: 0.5000 (2 samples)\n",
      "  Position 53: 1.0000 (2 samples)\n",
      "  Position 54: 0.5000 (2 samples)\n",
      "  Position 55: 0.5000 (2 samples)\n",
      "  Position 56: 1.0000 (2 samples)\n",
      "  Position 57: 0.5000 (2 samples)\n",
      "  Position 58: 0.5000 (2 samples)\n",
      "  Position 59: 1.0000 (2 samples)\n",
      "  Position 60: 1.0000 (2 samples)\n",
      "  Position 61: 1.0000 (2 samples)\n",
      "  Position 62: 0.5000 (2 samples)\n",
      "  Position 63: 1.0000 (2 samples)\n",
      "  Position 64: 1.0000 (2 samples)\n",
      "  Position 65: 1.0000 (2 samples)\n",
      "  Position 66: 1.0000 (2 samples)\n",
      "  Position 67: 1.0000 (2 samples)\n",
      "  Position 68: 1.0000 (2 samples)\n",
      "  Position 69: 0.5000 (2 samples)\n",
      "  Position 70: 0.5000 (2 samples)\n",
      "  Position 71: 1.0000 (2 samples)\n",
      "  Position 72: 0.5000 (2 samples)\n",
      "  Position 73: 1.0000 (2 samples)\n",
      "  Position 74: 1.0000 (2 samples)\n",
      "  Position 75: 1.0000 (2 samples)\n",
      "  Position 76: 0.5000 (2 samples)\n",
      "  Position 77: 0.5000 (2 samples)\n",
      "  Position 78: 1.0000 (2 samples)\n",
      "  Position 79: 0.5000 (2 samples)\n",
      "  Position 80: 0.5000 (2 samples)\n",
      "  Position 81: 1.0000 (2 samples)\n",
      "  Position 82: 0.5000 (2 samples)\n",
      "  Position 83: 0.5000 (2 samples)\n",
      "  Position 84: 0.5000 (2 samples)\n",
      "  Position 85: 0.0000 (2 samples)\n",
      "  Position 86: 0.5000 (2 samples)\n",
      "  Position 87: 1.0000 (2 samples)\n",
      "  Position 88: 0.5000 (2 samples)\n",
      "  Position 89: 0.5000 (2 samples)\n",
      "  Position 90: 0.5000 (2 samples)\n",
      "  Position 91: 0.5000 (2 samples)\n",
      "  Position 92: 0.5000 (2 samples)\n",
      "  Position 93: 0.5000 (2 samples)\n",
      "  Position 94: 0.5000 (2 samples)\n",
      "  Position 95: 1.0000 (2 samples)\n",
      "  Position 96: 1.0000 (2 samples)\n",
      "  Position 97: 1.0000 (2 samples)\n",
      "  Position 98: 1.0000 (2 samples)\n",
      "  Position 99: 1.0000 (2 samples)\n",
      "  Position 100: 1.0000 (2 samples)\n",
      "  Position 101: 1.0000 (2 samples)\n",
      "  Position 102: 1.0000 (2 samples)\n",
      "  Position 103: 1.0000 (2 samples)\n",
      "  Position 104: 0.5000 (2 samples)\n",
      "  Position 105: 1.0000 (2 samples)\n",
      "  Position 106: 1.0000 (2 samples)\n",
      "  Position 107: 1.0000 (2 samples)\n",
      "  Position 108: 1.0000 (1 samples)\n",
      "  Position 109: 1.0000 (1 samples)\n",
      "  Position 110: 0.0000 (1 samples)\n",
      "  Position 111: 1.0000 (1 samples)\n",
      "  Position 112: 1.0000 (1 samples)\n",
      "  Position 113: 1.0000 (1 samples)\n",
      "  Position 114: 1.0000 (1 samples)\n",
      "  Position 115: 1.0000 (1 samples)\n",
      "  Position 116: 1.0000 (1 samples)\n",
      "  Position 117: 1.0000 (1 samples)\n",
      "  Position 118: 1.0000 (1 samples)\n",
      "  Position 119: 1.0000 (1 samples)\n",
      "  Position 120: 1.0000 (1 samples)\n",
      "  Position 121: 1.0000 (1 samples)\n",
      "  Position 122: 1.0000 (1 samples)\n",
      "  Position 123: 1.0000 (1 samples)\n",
      "  Position 124: 1.0000 (1 samples)\n",
      "  Position 125: 1.0000 (1 samples)\n",
      "  Position 126: 1.0000 (1 samples)\n",
      "  Position 127: 1.0000 (1 samples)\n",
      "  Position 128: 1.0000 (1 samples)\n",
      "  Position 129: 1.0000 (1 samples)\n",
      "  Position 130: 1.0000 (1 samples)\n",
      "  Position 131: 1.0000 (1 samples)\n",
      "  Position 132: 1.0000 (1 samples)\n",
      "  Position 133: 1.0000 (1 samples)\n",
      "  Position 134: 0.0000 (1 samples)\n",
      "  Position 135: 1.0000 (1 samples)\n",
      "  Position 136: 0.0000 (1 samples)\n",
      "  Position 137: 1.0000 (1 samples)\n",
      "  Position 138: 1.0000 (1 samples)\n",
      "  Position 139: 0.0000 (1 samples)\n",
      "  Position 140: 0.0000 (1 samples)\n",
      "  Position 141: 1.0000 (1 samples)\n",
      "  Position 142: 0.0000 (1 samples)\n",
      "  Position 143: 0.0000 (1 samples)\n",
      "  Position 144: 1.0000 (1 samples)\n",
      "  Position 145: 0.0000 (1 samples)\n",
      "  Position 146: 0.0000 (1 samples)\n",
      "  Position 147: 1.0000 (1 samples)\n",
      "  Position 148: 0.0000 (1 samples)\n",
      "  Position 149: 1.0000 (1 samples)\n",
      "  Position 150: 1.0000 (1 samples)\n",
      "  Position 151: 1.0000 (1 samples)\n",
      "  Position 152: 1.0000 (1 samples)\n",
      "  Position 153: 1.0000 (1 samples)\n",
      "  Position 154: 1.0000 (1 samples)\n",
      "  Position 155: 1.0000 (1 samples)\n",
      "  Position 156: 1.0000 (1 samples)\n",
      "  Position 157: 1.0000 (1 samples)\n",
      "  Position 158: 1.0000 (1 samples)\n",
      "  Position 159: 1.0000 (1 samples)\n",
      "  Position 160: 1.0000 (1 samples)\n",
      "  Position 161: 1.0000 (1 samples)\n",
      "  Position 162: 1.0000 (1 samples)\n",
      "  Position 163: 1.0000 (1 samples)\n",
      "  Position 164: 1.0000 (1 samples)\n",
      "  Position 165: 1.0000 (1 samples)\n",
      "  Position 166: 1.0000 (1 samples)\n",
      "  Position 167: 1.0000 (1 samples)\n",
      "  Position 168: 1.0000 (1 samples)\n",
      "  Position 169: 1.0000 (1 samples)\n",
      "  Position 170: 1.0000 (1 samples)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Functional Example Display\n",
   "id": "77e9f6fe5d074154"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:03:28.102344Z",
     "start_time": "2025-07-30T08:03:28.097963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Show example predictions\n",
    "print_header(\"EXAMPLE PREDICTIONS WITH EXPLANATIONS\")\n",
    "\n",
    "examples = get_example_predictions(all_results, max_examples=5)\n",
    "\n",
    "for i, example in enumerate(examples):\n",
    "    print(f\"\\nExample {i + 1} ({example['section']}):\")\n",
    "    print(f\"Premise: {example['premise']}\")\n",
    "    print(f\"Hypothesis: {example['hypothesis']}\")\n",
    "    print(f\"Explanation: {example['explanation']}\")\n",
    "    print(f\"Predicted: {example['pred_label']}\")\n",
    "    print(f\"Gold: {example['gold_label']}\")\n",
    "    print(f\"Correct: {example['correct']}\")\n",
    "    print(\"-\" * 40)"
   ],
   "id": "70f5cb35a19e24c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXAMPLE PREDICTIONS WITH EXPLANATIONS\n",
      "============================================================\n",
      "\n",
      "Example 1 (presupposition_all_n_presupposition):\n",
      "Premise: All ten guys that proved to boast were divorcing.\n",
      "Hypothesis: There are exactly ten guys that proved to boast.\n",
      "Explanation: The premise \"All ten guys that proved to boast were divorcing\" triggers a presupposition that there are exactly ten guys who proved to boast. This is evident from the quantifier \"all ten,\" which assumes the precise number and existence of these individuals as a background condition for the statement to make sense. The hypothesis \"There are exactly ten guys that proved to boast\" directly aligns with and restates this presupposition. As a result, the truth of the premise requires the presupposition to hold, making the hypothesis follow logically from the premise.\n",
      "Predicted: entailment\n",
      "Gold: entailment\n",
      "Correct: True\n",
      "----------------------------------------\n",
      "\n",
      "Example 2 (presupposition_all_n_presupposition):\n",
      "Premise: All ten guys that proved to boast were divorcing.\n",
      "Hypothesis: There are exactly eleven guys that proved to boast.\n",
      "Explanation: The premise, \"All ten guys that proved to boast were divorcing,\" triggers a presupposition about the existence and exact number of guys who proved to boast. Specifically, it presupposes that there are exactly ten guys who proved to boast, as the phrase \"all ten guys\" quantifies and assumes this precise number without questioning it. This presupposition is a background assumption necessary for the premise to make sense. The hypothesis, \"There are exactly eleven guys that proved to boast,\" directly challenges this presupposition by asserting a different quantity—exactly eleven guys. As a result, the hypothesis contradicts the presupposition embedded in the premise, creating a clear inconsistency rather than following from or being neutral to it.\n",
      "Predicted: contradiction\n",
      "Gold: contradiction\n",
      "Correct: True\n",
      "----------------------------------------\n",
      "\n",
      "Example 3 (presupposition_both_presupposition):\n",
      "Premise: Both gloves that aren't loosening do fray.\n",
      "Hypothesis: There are exactly two gloves that aren't loosening\n",
      "Explanation: The premise \"Both gloves that aren't loosening do fray\" triggers several presuppositions. The word \"both\" presupposes that there are exactly two gloves that aren't loosening, as it inherently refers to a pair. This means the premise assumes the existence of precisely two such gloves without explicitly stating it, focusing instead on the property that these gloves do fray. The hypothesis \"There are exactly two gloves that aren't loosening\" directly asserts this presupposed quantity and existence. Since the hypothesis aligns with and follows from the presupposition embedded in the premise (specifically, the implication of \"both\"), it is entailed by the premise's presuppositions.\n",
      "Predicted: entailment\n",
      "Gold: entailment\n",
      "Correct: True\n",
      "----------------------------------------\n",
      "\n",
      "Example 4 (presupposition_both_presupposition):\n",
      "Premise: Both gloves that aren't loosening do fray.\n",
      "Hypothesis: There are exactly three gloves that aren't loosening.\n",
      "Explanation: The premise states, \"Both gloves that aren't loosening do fray.\" The word \"both\" in the premise presupposes that there are exactly two gloves that aren't loosening, as \"both\" typically implies a set of precisely two items. This presupposition is a background assumption necessary for the premise to make sense. The hypothesis, \"There are exactly three gloves that aren't loosening,\" directly challenges this presupposition by asserting that the number of such gloves is three, not two. Therefore, the hypothesis contradicts the presupposition embedded in the premise, as they cannot both be true simultaneously.\n",
      "Predicted: contradiction\n",
      "Gold: contradiction\n",
      "Correct: True\n",
      "----------------------------------------\n",
      "\n",
      "Example 5 (presupposition_change_of_state):\n",
      "Premise: The guest had found John.\n",
      "Hypothesis: John used to be in an unknown location.\n",
      "Explanation: The premise \"The guest had found John\" triggers a presupposition that John's location was previously unknown to the guest, as the act of \"finding\" someone inherently assumes that their whereabouts were not known prior to the discovery. This presupposition directly supports the hypothesis \"John used to be in an unknown location,\" which asserts that John was in a location that was not known at some point in the past. The hypothesis aligns with the presupposition from the premise, as the idea of John's location being unknown is a necessary background assumption for the premise to make sense. Therefore, the hypothesis follows logically from the presupposition triggered by the premise.\n",
      "Predicted: entailment\n",
      "Gold: entailment\n",
      "Correct: True\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Analysis and Conclusions\n",
   "id": "e399107f4cf13d87"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:03:28.168262Z",
     "start_time": "2025-07-30T08:03:28.162027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYSIS AND CONCLUSIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"Task 2.4 Implementation Summary:\")\n",
    "print(\"1. Implemented explanation-based CoT LLM for presupposition identification\")\n",
    "print(\"2. Used paradigm consistency as a reward measure combined with accuracy\")\n",
    "print(\"3. Evaluated on all 9 presupposition sections of ImpPres dataset\")\n",
    "print(\"4. Analyzed consistency patterns across paradigm transformations\")\n",
    "print()\n",
    "\n",
    "print(\"Key Findings:\")\n",
    "print(f\"- Overall accuracy: {overall_metrics['accuracy']:.4f}\")\n",
    "print(f\"- Overall consistency: {overall_metrics['consistency']:.4f}\")\n",
    "print(f\"- Combined score (α=0.7): {overall_metrics['combined_score']:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"Approach Explanation:\")\n",
    "print(\"- Used explanation-based prompting to improve presupposition understanding\")\n",
    "print(\"- Implemented paradigm consistency validation across transformations\")\n",
    "print(\"- Combined accuracy and consistency with α=0.7 weighting\")\n",
    "print(\"- Limited samples per section to control API costs\")\n",
    "print()\n",
    "\n",
    "print(\"Future Improvements:\")\n",
    "print(\"- Optimize DSPy program with few-shot examples\")\n",
    "print(\"- Implement more sophisticated consistency measures\")\n",
    "print(\"- Use larger sample sizes for more robust evaluation\")\n",
    "print(\"- Add comparison with multiple baseline models\")"
   ],
   "id": "22b5d36f6bf711ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ANALYSIS AND CONCLUSIONS\n",
      "============================================================\n",
      "Task 2.4 Implementation Summary:\n",
      "1. Implemented explanation-based CoT LLM for presupposition identification\n",
      "2. Used paradigm consistency as a reward measure combined with accuracy\n",
      "3. Evaluated on all 9 presupposition sections of ImpPres dataset\n",
      "4. Analyzed consistency patterns across paradigm transformations\n",
      "\n",
      "Key Findings:\n",
      "- Overall accuracy: 1.0000\n",
      "- Overall consistency: 0.4000\n",
      "- Combined score (α=0.7): 0.8200\n",
      "\n",
      "Approach Explanation:\n",
      "- Used explanation-based prompting to improve presupposition understanding\n",
      "- Implemented paradigm consistency validation across transformations\n",
      "- Combined accuracy and consistency with α=0.7 weighting\n",
      "- Limited samples per section to control API costs\n",
      "\n",
      "Future Improvements:\n",
      "- Optimize DSPy program with few-shot examples\n",
      "- Implement more sophisticated consistency measures\n",
      "- Use larger sample sizes for more robust evaluation\n",
      "- Add comparison with multiple baseline models\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "bc0b6a91923af235"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
